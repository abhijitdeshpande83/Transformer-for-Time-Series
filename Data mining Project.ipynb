{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latin-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "educated-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/abhijitdeshpande/Documents/Project/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collective-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2653 entries, 0 to 2652\n",
      "Data columns (total 67 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   SMA               2653 non-null   float64\n",
      " 1   EMA               2653 non-null   float64\n",
      " 2   MACD_Hist         2653 non-null   float64\n",
      " 3   MACD_Signal       2653 non-null   float64\n",
      " 4   MACD              2653 non-null   float64\n",
      " 5   SlowD             2653 non-null   float64\n",
      " 6   SlowK             2653 non-null   float64\n",
      " 7   RSI               2653 non-null   float64\n",
      " 8   ADX               2653 non-null   float64\n",
      " 9   CCI               2653 non-null   float64\n",
      " 10  Aroon Up          2653 non-null   float64\n",
      " 11  Aroon Down        2653 non-null   float64\n",
      " 12  Chaikin A/D       2653 non-null   float64\n",
      " 13  OBV               2653 non-null   float64\n",
      " 14  Real Middle Band  2653 non-null   float64\n",
      " 15  Real Upper Band   2653 non-null   float64\n",
      " 16  Real Lower Band   2653 non-null   float64\n",
      " 17  WMA               2653 non-null   float64\n",
      " 18  DEMA              2653 non-null   float64\n",
      " 19  TEMA              2653 non-null   float64\n",
      " 20  TRIMA             2653 non-null   float64\n",
      " 21  KAMA              2653 non-null   float64\n",
      " 22  FAMA              2653 non-null   float64\n",
      " 23  MAMA              2653 non-null   float64\n",
      " 24  T3                2653 non-null   float64\n",
      " 25  MACD_Signal.1     2653 non-null   float64\n",
      " 26  MACD.1            2653 non-null   float64\n",
      " 27  MACD_Hist.1       2653 non-null   float64\n",
      " 28  FastK             2653 non-null   float64\n",
      " 29  FastD             2653 non-null   float64\n",
      " 30  FastK.1           2653 non-null   float64\n",
      " 31  FastD.1           2653 non-null   float64\n",
      " 32  WILLR             2653 non-null   float64\n",
      " 33  ADXR              2653 non-null   float64\n",
      " 34  APO               2653 non-null   float64\n",
      " 35  PPO               2653 non-null   float64\n",
      " 36  MOM               2653 non-null   float64\n",
      " 37  BOP               2653 non-null   float64\n",
      " 38  CMO               2653 non-null   float64\n",
      " 39  ROC               2653 non-null   float64\n",
      " 40  ROCR              2653 non-null   float64\n",
      " 41  AROONOSC          2653 non-null   float64\n",
      " 42  MFI               2653 non-null   float64\n",
      " 43  TRIX              2653 non-null   float64\n",
      " 44  ULTOSC            2653 non-null   float64\n",
      " 45  DX                2653 non-null   float64\n",
      " 46  MINUS_DI          2653 non-null   float64\n",
      " 47  PLUS_DI           2653 non-null   float64\n",
      " 48  MINUS_DM          2653 non-null   float64\n",
      " 49  PLUS_DM           2653 non-null   float64\n",
      " 50  MIDPOINT          2653 non-null   float64\n",
      " 51  MIDPRICE          2653 non-null   float64\n",
      " 52  SAR               2653 non-null   float64\n",
      " 53  TRANGE            2653 non-null   float64\n",
      " 54  ATR               2653 non-null   float64\n",
      " 55  NATR              2653 non-null   float64\n",
      " 56  HT_TRENDLINE      2653 non-null   float64\n",
      " 57  LEAD SINE         2653 non-null   float64\n",
      " 58  SINE              2653 non-null   float64\n",
      " 59  TRENDMODE         2653 non-null   float64\n",
      " 60  DCPERIOD          2653 non-null   float64\n",
      " 61  HT_DCPHASE        2653 non-null   float64\n",
      " 62  QUADRATURE        2653 non-null   float64\n",
      " 63  PHASE             2653 non-null   float64\n",
      " 64  Volume            2653 non-null   float64\n",
      " 65  close             2653 non-null   float64\n",
      " 66  out               2653 non-null   int64  \n",
      "dtypes: float64(66), int64(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compact-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compressed-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Daily_Volatility(close,span0=20):\n",
    "    # simple percentage returns\n",
    "    df0=close.pct_change()\n",
    "    # 20 days, a month EWM's std as boundary\n",
    "    df0=df0.ewm(span=span0).std()\n",
    "    df0.dropna(inplace=True)\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacterial-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atr(stock, win=14):\n",
    "    \n",
    "    atr_df = pd.Series(index=stock.index)\n",
    "    high = pd.Series(adj.high.rolling( \\\n",
    "                     win, min_periods=win))\n",
    "    low = pd.Series(adj.low.rolling( \\\n",
    "                    win, min_periods=win))\n",
    "    close = pd.Series(adj.close.rolling( \\\n",
    "                      win, min_periods=win))    \n",
    "          \n",
    "    for i in range(len(stock.index)):\n",
    "        tr=np.max([(high[i] - low[i]), \\\n",
    "                  np.abs(high[i] - close[i]), \\\n",
    "                  np.abs(low[i] - close[i])], \\\n",
    "                  axis=0)\n",
    "        atr_df[i] = tr.sum() / win\n",
    "     \n",
    "    return  atr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "missing-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barriers():\n",
    "    #create a container\n",
    "    barriers = pd.DataFrame(columns=['days_passed', \n",
    "              'price', 'vert_barrier', \\\n",
    "              'top_barrier', 'bottom_barrier'], \\\n",
    "               index = daily_volatility.index)\n",
    "    for day, vol in daily_volatility.iteritems():\n",
    "        days_passed = len(daily_volatility.loc \\\n",
    "                      [daily_volatility.index[0] : day])\n",
    "        #set the vertical barrier \n",
    "        if ((days_passed + t_final) < len(daily_volatility.index) \\\n",
    "            and t_final != 0):\n",
    "            vert_barrier = daily_volatility.index[\n",
    "                                days_passed + t_final]\n",
    "        else:\n",
    "            vert_barrier = np.nan\n",
    "        #set the top barrier\n",
    "        if upper_lower_multipliers[0] > 0:\n",
    "            top_barrier = prices.loc[day] + prices.loc[day] * \\\n",
    "                          upper_lower_multipliers[0] * vol\n",
    "        else:\n",
    "            #set it to NaNs\n",
    "            top_barrier = pd.Series(index=prices.index)\n",
    "        #set the bottom barrier\n",
    "        if upper_lower_multipliers[1] > 0:\n",
    "            bottom_barrier = prices.loc[day] - prices.loc[day] * \\\n",
    "                          upper_lower_multipliers[1] * vol\n",
    "        else: \n",
    "            #set it to NaNs\n",
    "            bottom_barrier = pd.Series(index=prices.index)\n",
    "        barriers.loc[day, ['days_passed', 'price', \n",
    "            'vert_barrier','top_barrier', 'bottom_barrier']] = \\\n",
    "             days_passed, prices.loc[day], vert_barrier, \\\n",
    "             top_barrier, bottom_barrier\n",
    "    return barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vulnerable-limitation",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_2678/3886740384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#set the boundary of barriers, based on 20 days EWM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdaily_volatility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Daily_Volatility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# how many days we hold the stock which set the vertical barrier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#the up and low boundary multipliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "#set the boundary of barriers, based on 20 days EWM\n",
    "daily_volatility = get_Daily_Volatility(data.close)\n",
    "# how many days we hold the stock which set the vertical barrier\n",
    "t_final = 5\n",
    "#the up and low boundary multipliers\n",
    "upper_lower_multipliers = [1, 1]\n",
    "#allign the index\n",
    "prices = data.close[daily_volatility.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intermediate-flashing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_volatility' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_2678/643526980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbarriers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_barriers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_2678/310546165.py\u001b[0m in \u001b[0;36mget_barriers\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vert_barrier'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               'top_barrier', 'bottom_barrier'], \\\n\u001b[0;32m----> 6\u001b[0;31m                index = daily_volatility.index)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdaily_volatility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         days_passed = len(daily_volatility.loc \\\n",
      "\u001b[0;31mNameError\u001b[0m: name 'daily_volatility' is not defined"
     ]
    }
   ],
   "source": [
    "barriers = get_barriers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "short-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'barriers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_2678/3347129987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbarriers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'barriers' is not defined"
     ]
    }
   ],
   "source": [
    "barriers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interpreted-jenny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_passed</th>\n",
       "      <th>price</th>\n",
       "      <th>vert_barrier</th>\n",
       "      <th>top_barrier</th>\n",
       "      <th>bottom_barrier</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-15</th>\n",
       "      <td>1</td>\n",
       "      <td>5.116</td>\n",
       "      <td>2011-04-26</td>\n",
       "      <td>5.148842</td>\n",
       "      <td>5.083158</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18</th>\n",
       "      <td>2</td>\n",
       "      <td>5.006</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>5.111059</td>\n",
       "      <td>4.900941</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-19</th>\n",
       "      <td>3</td>\n",
       "      <td>5.032</td>\n",
       "      <td>2011-04-28</td>\n",
       "      <td>5.116934</td>\n",
       "      <td>4.947066</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-20</th>\n",
       "      <td>4</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>5.240737</td>\n",
       "      <td>5.059263</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-21</th>\n",
       "      <td>5</td>\n",
       "      <td>5.348</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>5.45933</td>\n",
       "      <td>5.23667</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           days_passed  price vert_barrier top_barrier bottom_barrier   out\n",
       "date                                                                       \n",
       "2011-04-15           1  5.116   2011-04-26    5.148842       5.083158  None\n",
       "2011-04-18           2  5.006   2011-04-27    5.111059       4.900941  None\n",
       "2011-04-19           3  5.032   2011-04-28    5.116934       4.947066  None\n",
       "2011-04-20           4   5.15   2011-04-29    5.240737       5.059263  None\n",
       "2011-04-21           5  5.348   2011-05-02     5.45933        5.23667  None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barriers['out'] = None\n",
    "barriers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-virus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "approximate-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels():\n",
    " \n",
    "    for i in range(len(barriers.index)):\n",
    "        start = barriers.index[i]\n",
    "        end = barriers.vert_barrier[i]\n",
    "        if pd.notna(end):\n",
    "            # assign the initial and final price\n",
    "            price_initial = barriers.price[start]\n",
    "            price_final = barriers.price[end]\n",
    "            # assign the top and bottom barriers\n",
    "            top_barrier = barriers.top_barrier[i]\n",
    "            bottom_barrier = barriers.bottom_barrier[i]\n",
    "            #set the profit taking and stop loss conditons\n",
    "            condition_pt = (barriers.price[start: end] >= \\\n",
    "             top_barrier).any()\n",
    "            condition_sl = (barriers.price[start: end] <= \\\n",
    "             bottom_barrier).any()\n",
    "            #assign the labels\n",
    "            if condition_pt: \n",
    "                barriers['out'][i] = 1\n",
    "            elif condition_sl: \n",
    "                barriers['out'][i] = -1    \n",
    "            else: \n",
    "                barriers['out'][i] = max(\n",
    "                          [(price_final - price_initial)/ \n",
    "                           (top_barrier - price_initial), \\\n",
    "                           (price_final - price_initial)/ \\\n",
    "                           (price_initial - bottom_barrier)],\\\n",
    "                            key=abs)\n",
    "                #barriers['out'][i] = 0\n",
    "    return \n",
    "get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statutory-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_passed</th>\n",
       "      <th>price</th>\n",
       "      <th>vert_barrier</th>\n",
       "      <th>top_barrier</th>\n",
       "      <th>bottom_barrier</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-04-15</th>\n",
       "      <td>1</td>\n",
       "      <td>5.116</td>\n",
       "      <td>2011-04-26</td>\n",
       "      <td>5.148842</td>\n",
       "      <td>5.083158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-18</th>\n",
       "      <td>2</td>\n",
       "      <td>5.006</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>5.111059</td>\n",
       "      <td>4.900941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-19</th>\n",
       "      <td>3</td>\n",
       "      <td>5.032</td>\n",
       "      <td>2011-04-28</td>\n",
       "      <td>5.116934</td>\n",
       "      <td>4.947066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-20</th>\n",
       "      <td>4</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>5.240737</td>\n",
       "      <td>5.059263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-21</th>\n",
       "      <td>5</td>\n",
       "      <td>5.348</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>5.45933</td>\n",
       "      <td>5.23667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-21</th>\n",
       "      <td>2520</td>\n",
       "      <td>744.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772.155134</td>\n",
       "      <td>716.084866</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-22</th>\n",
       "      <td>2521</td>\n",
       "      <td>719.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>746.864367</td>\n",
       "      <td>692.515633</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-23</th>\n",
       "      <td>2522</td>\n",
       "      <td>729.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>755.699903</td>\n",
       "      <td>703.100097</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-26</th>\n",
       "      <td>2523</td>\n",
       "      <td>738.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763.582902</td>\n",
       "      <td>712.817098</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-27</th>\n",
       "      <td>2524</td>\n",
       "      <td>704.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730.116127</td>\n",
       "      <td>679.363873</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2524 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           days_passed   price vert_barrier top_barrier bottom_barrier   out\n",
       "date                                                                        \n",
       "2011-04-15           1   5.116   2011-04-26    5.148842       5.083158     1\n",
       "2011-04-18           2   5.006   2011-04-27    5.111059       4.900941     1\n",
       "2011-04-19           3   5.032   2011-04-28    5.116934       4.947066     1\n",
       "2011-04-20           4    5.15   2011-04-29    5.240737       5.059263     1\n",
       "2011-04-21           5   5.348   2011-05-02     5.45933        5.23667     1\n",
       "...                ...     ...          ...         ...            ...   ...\n",
       "2021-04-21        2520  744.12          NaN  772.155134     716.084866  None\n",
       "2021-04-22        2521  719.69          NaN  746.864367     692.515633  None\n",
       "2021-04-23        2522   729.4          NaN  755.699903     703.100097  None\n",
       "2021-04-26        2523   738.2          NaN  763.582902     712.817098  None\n",
       "2021-04-27        2524  704.74          NaN  730.116127     679.363873  None\n",
       "\n",
       "[2524 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barriers['vert_barrier'] = barriers['vert_barrier'].map(lambda x:x)\n",
    "barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "refined-emphasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.000000    1393\n",
       "-1.000000     826\n",
       "-0.302231       1\n",
       " 0.740473       1\n",
       " 0.388588       1\n",
       "             ... \n",
       " 0.383283       1\n",
       " 0.734734       1\n",
       "-0.102836       1\n",
       "-0.098753       1\n",
       "-0.052990       1\n",
       "Name: out, Length: 301, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barriers.out.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "equivalent-bones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.set(title=barriers.out.iloc[10],\n",
    "       xlabel='date', ylabel='price')\n",
    "ax.plot(barriers.price[10: 20])\n",
    "start = barriers.index[10]\n",
    "end = barriers.vert_barrier[10]\n",
    "upper_barrier = barriers.top_barrier[10]\n",
    "lower_barrier = barriers.bottom_barrier[10]\n",
    "ax.plot([start, end], [upper_barrier, upper_barrier], 'r--');\n",
    "ax.plot([start, end], [lower_barrier, lower_barrier], 'r--');\n",
    "ax.plot([start, end], [(lower_barrier + upper_barrier)*0.5, \\\n",
    "                       (lower_barrier + upper_barrier)*0.5], 'r--');\n",
    "ax.plot([start, start], [lower_barrier, upper_barrier], 'r-');\n",
    "ax.plot([end, end], [lower_barrier, upper_barrier], 'r-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "boring-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data.drop(['date','close','out'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indonesian-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = pd.concat([feature,data.close,barriers[['out']]],axis=1)\n",
    "feature_set.dropna(how='any',inplace=True)\n",
    "label = feature_set[['out']].applymap(lambda x:1 if x>=1 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adult-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_ = feature_set.drop('out',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "chemical-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "scale = StandardScaler()\n",
    "scaled_data = scale.fit_transform(feature_set_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sophisticated-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from tscv import GapKFold\n",
    "from tscv import gap_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nonprofit-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = gap_train_test_split(scaled_data, label, test_size=0.2, gap_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "union-interview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf',C=1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "political-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GapKFold(n_splits=5, gap_before=10, gap_after=10)\n",
    "scores = cross_val_score(clf, X_test, y_test, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aggregate-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686622807017543"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "selective-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='crest')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-leather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hidden-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights(d,size):\n",
    "    # thres>0 drops insignificant weights\n",
    "    w=[1.]\n",
    "    for k in range(1,size):\n",
    "        w_ = -w[-1]/k*(d-k+1)\n",
    "        w.append(w_)\n",
    "    w=np.array(w[::-1]).reshape(-1,1)\n",
    "    return w \n",
    "\n",
    "#getWeights(0.1, s_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unavailable-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.69462519e-05],\n",
       "       [-1.69536435e-05],\n",
       "       [-1.69610413e-05],\n",
       "       ...,\n",
       "       [-4.50000000e-02],\n",
       "       [-1.00000000e-01],\n",
       "       [ 1.00000000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWeights(0.1, barriers.price.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sexual-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    " def fracDiff(series, d, thres=0.01):\n",
    "    '''\n",
    "    Increasing width window, with treatment of NaNs\n",
    "    Note 1: For thres=1, nothing is skipped\n",
    "    Note 2: d can be any positive fractional, not necessarily\n",
    "        bounded between [0,1]\n",
    "    '''\n",
    "    #1) Compute weights for the longest series\n",
    "    w=getWeights(d, series.shape[0])\n",
    "    #bp()\n",
    "    #2) Determine initial calcs to be skipped based on weight-loss threshold\n",
    "    w_=np.cumsum(abs(w))\n",
    "    w_ /= w_[-1]\n",
    "    skip = w_[w_>thres].shape[0]\n",
    "    #3) Apply weights to values\n",
    "    df={}\n",
    "    for name in series.columns:\n",
    "        seriesF, df_=series[[name]].fillna(method='ffill').dropna(), pd.Series()\n",
    "        for iloc in range(skip, seriesF.shape[0]):\n",
    "            loc=seriesF.index[iloc]\n",
    "            test_val = series.loc[loc,name] # must resample if duplicate index\n",
    "            if isinstance(test_val, (pd.Series, pd.DataFrame)):\n",
    "                test_val = test_val.resample('1m').mean()\n",
    "            if not np.isfinite(test_val).any(): continue # exclude NAs\n",
    "            try:\n",
    "                df_.loc[loc]=np.dot(w[-(iloc+1):,:].T, seriesF.loc[:loc])[0,0]\n",
    "            except:\n",
    "                continue\n",
    "        df[name]=df_.copy(deep=True)\n",
    "    df=pd.concat(df,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dried-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_d = fracDiff(data[['close']], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "improved-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_d.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "facial-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2524,), (2196, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barriers.price.shape, f_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adopted-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = pd.concat([feature,barriers[['out']],f_d],axis=1)\n",
    "feature_set.dropna(how='any',inplace=True)\n",
    "label = feature_set[['out']].applymap(lambda x:1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "imperial-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_ = feature_set.drop('out',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "identical-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "scale = StandardScaler()\n",
    "scaled_data = scale.fit_transform(feature_set_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "french-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from tscv import GapKFold\n",
    "from tscv import gap_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "graphic-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = gap_train_test_split(scaled_data, label, test_size=0.2, gap_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "temporal-worst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5600961538461539"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='poly',degree=2,C=1)\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "exciting-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.43      0.40       139\n",
      "           1       0.69      0.62      0.65       277\n",
      "\n",
      "    accuracy                           0.56       416\n",
      "   macro avg       0.53      0.53      0.53       416\n",
      "weighted avg       0.58      0.56      0.57       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "improving-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GapKFold(n_splits=10, gap_before=5, gap_after=5)\n",
    "scores = cross_val_score(clf, X_test, y_test, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-ensemble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "regular-geneva",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import alpha_vantage\n",
    "api_key = 'SXJIW6MO6ZIEYB0N'\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "domestic-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries(key=api_key, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "broad-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_features(technical_feature,company='TSLA', interval='daily', period=200, series_type='Close'):\n",
    "    data, meta_data = technical_feature(company, interval=interval, time_period= period, series_type=series_type)\n",
    "    return data\n",
    "\n",
    "def other_features(technical_feature,company='TSLA', interval='daily'):\n",
    "    data, meta_data = technical_feature(company, interval=interval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "mysterious-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, meta = ts.get_daily('TSLA',outputsize='full')\n",
    "adj['time'] = adj.index\n",
    "adj.rename(columns={'4. close':'close', '2. high':'high','3. low':'low','1. open':'open', '5. volume':'vol'},inplace=True)\n",
    "close = adj[['close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "transsexual-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "close['MA'] = ((adj['close']+adj['high']+adj['low'])/3).rolling(window=20).mean()\n",
    "close['std'] = ((adj['close']+adj['high']+adj['low'])/3).rolling(window=20).std()\n",
    "close['lower'] = close['MA']-(close['std']*2)\n",
    "close['upper'] = close['MA']+(close['std']*2)\n",
    "close[['MA','close','lower','upper']].plot(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "authorized-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_d.index = pd.to_datetime(f_d.index)\n",
    "close = pd.concat([close,f_d],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "instructional-gathering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "close['MA'] = ((adj['close']+adj['high']+adj['low'])/3).rolling(window=20).mean()\n",
    "close['std'] = ((adj['close']+adj['high']+adj['low'])/3).rolling(window=20).std()\n",
    "close['lower'] = close['MA']-(close['std']*2)\n",
    "close['upper'] = close['MA']+(close['std']*2)\n",
    "close[['MA','close','lower','upper']].plot(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D as MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "alleged-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'SMA', 'EMA', 'MACD', 'MACD_Signal', 'MACD_Hist', 'SlowK',\n",
       "       'SlowD', 'RSI', 'ADX', 'CCI', 'Aroon Down', 'Aroon Up', 'Chaikin A/D',\n",
       "       'OBV', 'Real Lower Band', 'Real Upper Band', 'Real Middle Band', 'WMA',\n",
       "       'DEMA', 'TEMA', 'TRIMA', 'KAMA', 'MAMA', 'FAMA', 'T3', 'MACD.1',\n",
       "       'MACD_Hist.1', 'MACD_Signal.1', 'FastK', 'FastD', 'FastD.1', 'FastK.1',\n",
       "       'WILLR', 'ADXR', 'APO', 'PPO', 'MOM', 'BOP', 'CMO', 'ROC', 'ROCR',\n",
       "       'AROONOSC', 'MFI', 'TRIX', 'ULTOSC', 'DX', 'MINUS_DI', 'PLUS_DI',\n",
       "       'MINUS_DM', 'PLUS_DM', 'MIDPOINT', 'MIDPRICE', 'SAR', 'TRANGE', 'ATR',\n",
       "       'NATR', 'HT_TRENDLINE', 'SINE', 'LEAD SINE', 'TRENDMODE', 'DCPERIOD',\n",
       "       'HT_DCPHASE', 'PHASE', 'QUADRATURE', 'close', 'out'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "satisfactory-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[['SMA','MACD','T3','OBV','ADX','Aroon Up','Aroon Down','RSI','close','out']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "shaped-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['date','out'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "rocky-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = new_data.drop(['out'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "proper-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data[['out']].applymap(lambda x:1 if x>=1 else 0)\n",
    "#label = new_data['close']\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "authorized-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_reshaped = scaled_data.reshape(2526,1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cutting-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2526, 65)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "homeless-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-clinic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "tutorial-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 846, 1048]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "relative-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,label,test_size=0.25,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "combined-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 65)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "missing-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-79841c182ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(tfl.Dense(100, input_dim=65, activation='relu'))\n",
    "model.add(tfl.Flatten())\n",
    "model.add(tfl.BatchNormalization())\n",
    "model.add(tfl.Dropout(0.5))\n",
    "model.add(tfl.Dense(50,activation='relu'))\n",
    "model.add(tfl.Dropout(0.4))\n",
    "model.add(tfl.Dense(10,activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(tfl.Dense(10,activation='relu'))\n",
    "model.add(tfl.Dense(6,activation='relu'))\n",
    "model.add(tfl.Dense(1,activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=20,batch_size=120,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "industrial-retail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "rural-backing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24202916, 0.2431671 , 0.24392137, 0.24403766, 0.2467078 ,\n",
       "       0.24684608, 0.24724042, 0.24726367, 0.24734962, 0.2476345 ,\n",
       "       0.24767873, 0.24775264, 0.24785116, 0.2482391 , 0.2482909 ,\n",
       "       0.24833933, 0.24834892, 0.24845022, 0.24855405, 0.24855474,\n",
       "       0.24862641, 0.24868926, 0.248752  , 0.24925026, 0.24925473,\n",
       "       0.24934235, 0.24980196, 0.24997729, 0.25002092, 0.25007424,\n",
       "       0.2500982 , 0.2501878 , 0.25019747, 0.25043762, 0.25086504,\n",
       "       0.2509138 , 0.2510527 , 0.25128037, 0.25189894, 0.25224686,\n",
       "       0.2525791 , 0.25396308, 0.25477642, 0.25716078, 0.25800905,\n",
       "       0.25884593, 0.25899768, 0.260056  , 0.26181078, 0.26211947,\n",
       "       0.26256928, 0.2644605 , 0.26460874, 0.2651248 , 0.26546752,\n",
       "       0.26597497, 0.2669782 , 0.26749852, 0.267752  , 0.26818264,\n",
       "       0.2684702 , 0.26869428, 0.26889783, 0.26930636, 0.26935163,\n",
       "       0.26940596, 0.26953888, 0.2696203 , 0.26974517, 0.27017257,\n",
       "       0.27082795, 0.2710947 , 0.27130112, 0.27171522, 0.27178714,\n",
       "       0.27218378, 0.2732263 , 0.2734698 , 0.27655455, 0.2773515 ,\n",
       "       0.2782934 , 0.2788635 , 0.27909514, 0.27949095, 0.27959514,\n",
       "       0.28017294, 0.28066474, 0.2808333 , 0.28086856, 0.28164107,\n",
       "       0.28324613, 0.28397614, 0.28710994, 0.28799903, 0.29265273,\n",
       "       0.2940578 , 0.29429618, 0.29470536, 0.29556274, 0.2960046 ,\n",
       "       0.29699105, 0.29807657, 0.29818225, 0.29900423, 0.2990931 ,\n",
       "       0.29916126, 0.29916638, 0.29918635, 0.29930377, 0.2994585 ,\n",
       "       0.3006351 , 0.3014148 , 0.3018952 , 0.30222657, 0.30228618,\n",
       "       0.30251724, 0.30253857, 0.30257204, 0.30299348, 0.30346143,\n",
       "       0.30350477, 0.30373454, 0.30397892, 0.30453762, 0.30481237,\n",
       "       0.30489504, 0.3061046 , 0.30615056, 0.30651438, 0.3067289 ,\n",
       "       0.30698997, 0.31013754, 0.3106447 , 0.31064546, 0.3108466 ,\n",
       "       0.31093842, 0.31099105, 0.31108963, 0.31150866, 0.311755  ,\n",
       "       0.31216305, 0.3124584 , 0.31339425, 0.31384793, 0.31431472,\n",
       "       0.31501678, 0.315158  , 0.31519043, 0.31614852, 0.31619728,\n",
       "       0.3162151 , 0.31651437, 0.31706136, 0.31708997, 0.31734136,\n",
       "       0.31753242, 0.31756702, 0.31782076, 0.31854737, 0.31870133,\n",
       "       0.3187554 , 0.31893897, 0.31925496, 0.31955287, 0.31970522,\n",
       "       0.31974328, 0.31995642, 0.3200077 , 0.32013917, 0.32031137,\n",
       "       0.3209407 , 0.32131368, 0.32186764, 0.32228035, 0.32229412,\n",
       "       0.3231871 , 0.32326692, 0.32329237, 0.32394952, 0.3241495 ,\n",
       "       0.324856  , 0.32551038, 0.3257832 , 0.32655305, 0.32741812,\n",
       "       0.3287993 , 0.33031687, 0.33071613, 0.33092898, 0.33317566,\n",
       "       0.3345893 , 0.33469307, 0.33623004, 0.33656323, 0.336646  ,\n",
       "       0.3370995 , 0.33773172, 0.33806163, 0.3380745 , 0.33820885,\n",
       "       0.33946872, 0.3404385 , 0.34114605, 0.34196538, 0.3422721 ,\n",
       "       0.3426087 , 0.3428797 , 0.3429563 , 0.34330282, 0.3434614 ,\n",
       "       0.34461403, 0.34490615, 0.34523785, 0.34525937, 0.34579402,\n",
       "       0.34648967, 0.34657997, 0.34820187, 0.348468  , 0.34855118,\n",
       "       0.34872094, 0.34899276, 0.34951583, 0.3496456 , 0.35141742,\n",
       "       0.35229164, 0.3523156 , 0.35235   , 0.35334295, 0.35425234,\n",
       "       0.3549005 , 0.3553717 , 0.35577667, 0.35632277, 0.35641658,\n",
       "       0.35642642, 0.3566513 , 0.35708123, 0.35712102, 0.35715273,\n",
       "       0.35776782, 0.35834342, 0.3586567 , 0.35988927, 0.3606554 ,\n",
       "       0.3608039 , 0.36092967, 0.3613065 , 0.36169222, 0.36177358,\n",
       "       0.36256778, 0.36387038, 0.3643644 , 0.36536264, 0.36581546,\n",
       "       0.3658398 , 0.36587268, 0.366757  , 0.3670537 , 0.36787173,\n",
       "       0.36792508, 0.36813846, 0.36838275, 0.36895108, 0.3701596 ,\n",
       "       0.3711924 , 0.37144518, 0.37177423, 0.37183625, 0.37325674,\n",
       "       0.37392786, 0.37425452, 0.3749218 , 0.3749503 , 0.3759038 ,\n",
       "       0.37597683, 0.3761741 , 0.37708706, 0.37845573, 0.37880233,\n",
       "       0.37986892, 0.38082978, 0.38114735, 0.38338   , 0.3845715 ,\n",
       "       0.3851508 , 0.38534015, 0.385827  , 0.3861658 , 0.38653576,\n",
       "       0.3867612 , 0.38744983, 0.38931206, 0.38931525, 0.39160424,\n",
       "       0.3923    , 0.3932915 , 0.39385542, 0.3943892 , 0.39491048,\n",
       "       0.39524746, 0.39971238, 0.3999304 , 0.40233323, 0.4046427 ,\n",
       "       0.40668112, 0.40907192, 0.41114414, 0.4112285 , 0.47366932,\n",
       "       0.47404486, 0.4787866 , 0.4790912 , 0.48037145, 0.4825215 ,\n",
       "       0.482965  , 0.48630333, 0.48775223, 0.48780367, 0.48829672,\n",
       "       0.48862284, 0.48874557, 0.48906782, 0.49144515, 0.4919755 ,\n",
       "       0.49298787, 0.4937384 , 0.49713758, 0.49725714, 0.49748695,\n",
       "       0.4989937 , 0.5004295 , 0.5007277 , 0.5009945 , 0.5010614 ,\n",
       "       0.5014319 , 0.50347805, 0.50415784, 0.50458807, 0.5047639 ,\n",
       "       0.5053189 , 0.5053234 , 0.505666  , 0.50656056, 0.50691205,\n",
       "       0.50806093, 0.50842106, 0.5089167 , 0.5114023 , 0.511628  ,\n",
       "       0.5120777 , 0.5123521 , 0.5129501 , 0.51351947, 0.5139566 ,\n",
       "       0.5145346 , 0.5152869 , 0.51592374, 0.51689464, 0.51755595,\n",
       "       0.51781076, 0.5178737 , 0.5183009 , 0.51855004, 0.5197508 ,\n",
       "       0.52274364, 0.5233703 , 0.5255939 , 0.5259514 , 0.5278232 ,\n",
       "       0.5322946 , 0.5345203 , 0.5382058 , 0.53859293, 0.5393154 ,\n",
       "       0.5398712 , 0.54002786, 0.54226416, 0.5432614 , 0.5435481 ,\n",
       "       0.54496354, 0.5485041 , 0.5501389 , 0.55128855, 0.5531725 ,\n",
       "       0.5536418 , 0.55933255, 0.55943626, 0.56646067, 0.5943372 ,\n",
       "       0.5956929 , 0.6000291 , 0.6540946 , 0.65445554, 0.6625584 ,\n",
       "       0.68773824, 0.7249733 , 0.77713394, 0.8350852 , 0.8598057 ,\n",
       "       0.9010135 , 0.9695908 , 0.96972924, 0.9726991 , 0.9964016 ,\n",
       "       0.99667895, 0.99707717, 0.99800074, 0.9994831 , 0.99974453,\n",
       "       0.99982274, 0.999958  , 0.9999628 , 0.9999666 , 0.99998724,\n",
       "       0.99999285, 0.99999815, 0.99999976, 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "english-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5531725 ],\n",
       "       [0.5501389 ],\n",
       "       [0.5536418 ],\n",
       "       [0.5485041 ],\n",
       "       [0.52274364],\n",
       "       [0.5010614 ],\n",
       "       [0.5139566 ],\n",
       "       [0.5053234 ],\n",
       "       [0.49713758],\n",
       "       [0.48775223],\n",
       "       [0.50415784],\n",
       "       [0.511628  ],\n",
       "       [0.50458807],\n",
       "       [0.4919755 ],\n",
       "       [0.5004295 ],\n",
       "       [0.5053189 ],\n",
       "       [0.49725714],\n",
       "       [0.49144515],\n",
       "       [0.48862284],\n",
       "       [0.4825215 ],\n",
       "       [0.48906782],\n",
       "       [0.505666  ],\n",
       "       [0.5089167 ],\n",
       "       [0.5114023 ],\n",
       "       [0.50656056],\n",
       "       [0.5178737 ],\n",
       "       [0.5152869 ],\n",
       "       [0.5183009 ],\n",
       "       [0.5145346 ],\n",
       "       [0.5009945 ],\n",
       "       [0.48874557],\n",
       "       [0.48037145],\n",
       "       [0.48780367],\n",
       "       [0.482965  ],\n",
       "       [0.47404486],\n",
       "       [0.4790912 ],\n",
       "       [0.47366932],\n",
       "       [0.4787866 ],\n",
       "       [0.48630333],\n",
       "       [0.49298787],\n",
       "       [0.5007277 ],\n",
       "       [0.50806093],\n",
       "       [0.4989937 ],\n",
       "       [0.5014319 ],\n",
       "       [0.49748695],\n",
       "       [0.5123521 ],\n",
       "       [0.5047639 ],\n",
       "       [0.51351947],\n",
       "       [0.5393154 ],\n",
       "       [0.54496354],\n",
       "       [0.5432614 ],\n",
       "       [0.5382058 ],\n",
       "       [0.5255939 ],\n",
       "       [0.51689464],\n",
       "       [0.5129501 ],\n",
       "       [0.50842106],\n",
       "       [0.5120777 ],\n",
       "       [0.50347805],\n",
       "       [0.4937384 ],\n",
       "       [0.48829672],\n",
       "       [0.50691205],\n",
       "       [0.51855004],\n",
       "       [0.53859293],\n",
       "       [0.5322946 ],\n",
       "       [0.5259514 ],\n",
       "       [0.5435481 ],\n",
       "       [0.54002786],\n",
       "       [0.5345203 ],\n",
       "       [0.5398712 ],\n",
       "       [0.51781076],\n",
       "       [0.5197508 ],\n",
       "       [0.51755595],\n",
       "       [0.51592374],\n",
       "       [0.5278232 ],\n",
       "       [0.68773824],\n",
       "       [0.5233703 ],\n",
       "       [0.54226416],\n",
       "       [0.56646067],\n",
       "       [0.65445554],\n",
       "       [0.6625584 ],\n",
       "       [0.6540946 ],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.5956929 ],\n",
       "       [0.55933255],\n",
       "       [0.55943626],\n",
       "       [0.5943372 ],\n",
       "       [0.6000291 ],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.8598057 ],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.77713394],\n",
       "       [0.55128855],\n",
       "       [0.99667895],\n",
       "       [0.9695908 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.9010135 ],\n",
       "       [0.99974453],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.99999976],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.9999628 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.9964016 ],\n",
       "       [0.99999976],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.99999815],\n",
       "       [0.999958  ],\n",
       "       [0.99999285],\n",
       "       [0.99982274],\n",
       "       [0.99800074],\n",
       "       [0.9999666 ],\n",
       "       [0.9994831 ],\n",
       "       [0.99998724],\n",
       "       [0.9726991 ],\n",
       "       [0.99707717],\n",
       "       [0.55128855],\n",
       "       [0.96972924],\n",
       "       [0.55128855],\n",
       "       [0.8350852 ],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.55128855],\n",
       "       [0.33031687],\n",
       "       [0.38114735],\n",
       "       [0.31519043],\n",
       "       [0.34525937],\n",
       "       [0.31708997],\n",
       "       [0.31995642],\n",
       "       [0.3241495 ],\n",
       "       [0.3162151 ],\n",
       "       [0.30373454],\n",
       "       [0.29556274],\n",
       "       [0.31925496],\n",
       "       [0.29916126],\n",
       "       [0.3018952 ],\n",
       "       [0.30257204],\n",
       "       [0.30453762],\n",
       "       [0.3108466 ],\n",
       "       [0.31501678],\n",
       "       [0.366757  ],\n",
       "       [0.3566513 ],\n",
       "       [0.29900423],\n",
       "       [0.31150866],\n",
       "       [0.31013754],\n",
       "       [0.32228035],\n",
       "       [0.3345893 ],\n",
       "       [0.3061046 ],\n",
       "       [0.3370995 ],\n",
       "       [0.35776782],\n",
       "       [0.39524746],\n",
       "       [0.40907192],\n",
       "       [0.40668112],\n",
       "       [0.7249733 ],\n",
       "       [0.39160424],\n",
       "       [0.39971238],\n",
       "       [0.38653576],\n",
       "       [0.4112285 ],\n",
       "       [0.37708706],\n",
       "       [0.40233323],\n",
       "       [0.3867612 ],\n",
       "       [0.41114414],\n",
       "       [0.3608039 ],\n",
       "       [0.38534015],\n",
       "       [0.4046427 ],\n",
       "       [0.3999304 ],\n",
       "       [0.3851508 ],\n",
       "       [0.34899276],\n",
       "       [0.34579402],\n",
       "       [0.3422721 ],\n",
       "       [0.32655305],\n",
       "       [0.3613065 ],\n",
       "       [0.3845715 ],\n",
       "       [0.3861658 ],\n",
       "       [0.38338   ],\n",
       "       [0.38931206],\n",
       "       [0.3943892 ],\n",
       "       [0.385827  ],\n",
       "       [0.3923    ],\n",
       "       [0.38931525],\n",
       "       [0.3749218 ],\n",
       "       [0.37425452],\n",
       "       [0.36895108],\n",
       "       [0.3749503 ],\n",
       "       [0.37880233],\n",
       "       [0.3643644 ],\n",
       "       [0.39491048],\n",
       "       [0.39385542],\n",
       "       [0.3932915 ],\n",
       "       [0.38744983],\n",
       "       [0.3658398 ],\n",
       "       [0.3759038 ],\n",
       "       [0.36256778],\n",
       "       [0.35141742],\n",
       "       [0.33806163],\n",
       "       [0.35334295],\n",
       "       [0.35712102],\n",
       "       [0.3701596 ],\n",
       "       [0.36587268],\n",
       "       [0.36536264],\n",
       "       [0.38082978],\n",
       "       [0.37845573],\n",
       "       [0.37986892],\n",
       "       [0.3711924 ],\n",
       "       [0.3606554 ],\n",
       "       [0.35834342],\n",
       "       [0.37392786],\n",
       "       [0.3761741 ],\n",
       "       [0.37144518],\n",
       "       [0.36092967],\n",
       "       [0.34820187],\n",
       "       [0.33656323],\n",
       "       [0.34855118],\n",
       "       [0.34461403],\n",
       "       [0.336646  ],\n",
       "       [0.33092898],\n",
       "       [0.34114605],\n",
       "       [0.35425234],\n",
       "       [0.34951583],\n",
       "       [0.3496456 ],\n",
       "       [0.35715273],\n",
       "       [0.35988927],\n",
       "       [0.3523156 ],\n",
       "       [0.35577667],\n",
       "       [0.34872094],\n",
       "       [0.3404385 ],\n",
       "       [0.3428797 ],\n",
       "       [0.35632277],\n",
       "       [0.3434614 ],\n",
       "       [0.35642642],\n",
       "       [0.34196538],\n",
       "       [0.3426087 ],\n",
       "       [0.3257832 ],\n",
       "       [0.34648967],\n",
       "       [0.36177358],\n",
       "       [0.35235   ],\n",
       "       [0.33946872],\n",
       "       [0.3549005 ],\n",
       "       [0.34490615],\n",
       "       [0.35229164],\n",
       "       [0.3586567 ],\n",
       "       [0.36581546],\n",
       "       [0.3553717 ],\n",
       "       [0.34657997],\n",
       "       [0.35708123],\n",
       "       [0.36838275],\n",
       "       [0.3670537 ],\n",
       "       [0.37183625],\n",
       "       [0.37177423],\n",
       "       [0.36387038],\n",
       "       [0.36792508],\n",
       "       [0.36169222],\n",
       "       [0.36787173],\n",
       "       [0.37325674],\n",
       "       [0.37597683],\n",
       "       [0.36813846],\n",
       "       [0.35641658],\n",
       "       [0.348468  ],\n",
       "       [0.34523785],\n",
       "       [0.33317566],\n",
       "       [0.34330282],\n",
       "       [0.33820885],\n",
       "       [0.31756702],\n",
       "       [0.33071613],\n",
       "       [0.3287993 ],\n",
       "       [0.32551038],\n",
       "       [0.311755  ],\n",
       "       [0.3187554 ],\n",
       "       [0.31614852],\n",
       "       [0.3209407 ],\n",
       "       [0.33773172],\n",
       "       [0.3429563 ],\n",
       "       [0.33623004],\n",
       "       [0.3380745 ],\n",
       "       [0.33469307],\n",
       "       [0.31651437],\n",
       "       [0.31108963],\n",
       "       [0.30698997],\n",
       "       [0.30228618],\n",
       "       [0.30397892],\n",
       "       [0.31384793],\n",
       "       [0.30350477],\n",
       "       [0.29807657],\n",
       "       [0.30615056],\n",
       "       [0.31064546],\n",
       "       [0.30299348],\n",
       "       [0.3006351 ],\n",
       "       [0.2940578 ],\n",
       "       [0.29930377],\n",
       "       [0.29429618],\n",
       "       [0.29265273],\n",
       "       [0.2960046 ],\n",
       "       [0.2990931 ],\n",
       "       [0.29918635],\n",
       "       [0.29818225],\n",
       "       [0.30481237],\n",
       "       [0.30251724],\n",
       "       [0.30346143],\n",
       "       [0.3014148 ],\n",
       "       [0.29916638],\n",
       "       [0.2994585 ],\n",
       "       [0.30222657],\n",
       "       [0.30489504],\n",
       "       [0.30651438],\n",
       "       [0.31216305],\n",
       "       [0.32326692],\n",
       "       [0.315158  ],\n",
       "       [0.31099105],\n",
       "       [0.31339425],\n",
       "       [0.31706136],\n",
       "       [0.32013917],\n",
       "       [0.32031137],\n",
       "       [0.32186764],\n",
       "       [0.31970522],\n",
       "       [0.32131368],\n",
       "       [0.31870133],\n",
       "       [0.31734136],\n",
       "       [0.32229412],\n",
       "       [0.31854737],\n",
       "       [0.31753242],\n",
       "       [0.31893897],\n",
       "       [0.31619728],\n",
       "       [0.31431472],\n",
       "       [0.324856  ],\n",
       "       [0.31974328],\n",
       "       [0.3231871 ],\n",
       "       [0.32741812],\n",
       "       [0.32394952],\n",
       "       [0.31955287],\n",
       "       [0.3124584 ],\n",
       "       [0.31782076],\n",
       "       [0.3200077 ],\n",
       "       [0.32329237],\n",
       "       [0.3106447 ],\n",
       "       [0.31093842],\n",
       "       [0.3067289 ],\n",
       "       [0.30253857],\n",
       "       [0.29470536],\n",
       "       [0.29699105],\n",
       "       [0.28799903],\n",
       "       [0.28710994],\n",
       "       [0.28324613],\n",
       "       [0.28397614],\n",
       "       [0.28164107],\n",
       "       [0.27655455],\n",
       "       [0.25899768],\n",
       "       [0.26211947],\n",
       "       [0.27218378],\n",
       "       [0.27017257],\n",
       "       [0.26889783],\n",
       "       [0.26181078],\n",
       "       [0.260056  ],\n",
       "       [0.25884593],\n",
       "       [0.2525791 ],\n",
       "       [0.25086504],\n",
       "       [0.24997729],\n",
       "       [0.25477642],\n",
       "       [0.24980196],\n",
       "       [0.24392137],\n",
       "       [0.2476345 ],\n",
       "       [0.248752  ],\n",
       "       [0.24726367],\n",
       "       [0.2482909 ],\n",
       "       [0.25043762],\n",
       "       [0.25002092],\n",
       "       [0.2501878 ],\n",
       "       [0.2509138 ],\n",
       "       [0.24925473],\n",
       "       [0.24855474],\n",
       "       [0.24868926],\n",
       "       [0.25019747],\n",
       "       [0.24855405],\n",
       "       [0.2500982 ],\n",
       "       [0.24785116],\n",
       "       [0.2467078 ],\n",
       "       [0.2482391 ],\n",
       "       [0.24684608],\n",
       "       [0.24734962],\n",
       "       [0.24862641],\n",
       "       [0.24845022],\n",
       "       [0.2510527 ],\n",
       "       [0.25189894],\n",
       "       [0.25007424],\n",
       "       [0.25128037],\n",
       "       [0.24934235],\n",
       "       [0.24834892],\n",
       "       [0.24925026],\n",
       "       [0.25224686],\n",
       "       [0.2431671 ],\n",
       "       [0.24202916],\n",
       "       [0.24403766],\n",
       "       [0.24767873],\n",
       "       [0.24724042],\n",
       "       [0.24775264],\n",
       "       [0.24833933],\n",
       "       [0.25396308],\n",
       "       [0.26953888],\n",
       "       [0.2710947 ],\n",
       "       [0.26930636],\n",
       "       [0.2732263 ],\n",
       "       [0.27171522],\n",
       "       [0.28086856],\n",
       "       [0.27909514],\n",
       "       [0.2808333 ],\n",
       "       [0.28017294],\n",
       "       [0.28066474],\n",
       "       [0.27949095],\n",
       "       [0.26869428],\n",
       "       [0.27082795],\n",
       "       [0.27130112],\n",
       "       [0.26940596],\n",
       "       [0.2734698 ],\n",
       "       [0.27959514],\n",
       "       [0.2788635 ],\n",
       "       [0.2773515 ],\n",
       "       [0.2782934 ],\n",
       "       [0.2696203 ],\n",
       "       [0.2669782 ],\n",
       "       [0.26818264],\n",
       "       [0.26597497],\n",
       "       [0.26974517],\n",
       "       [0.2684702 ],\n",
       "       [0.267752  ],\n",
       "       [0.26935163],\n",
       "       [0.26749852],\n",
       "       [0.2644605 ],\n",
       "       [0.27178714],\n",
       "       [0.2651248 ],\n",
       "       [0.26460874],\n",
       "       [0.26546752],\n",
       "       [0.26256928],\n",
       "       [0.25716078],\n",
       "       [0.25800905]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "israeli-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in prediction:\n",
    "    if i>0.5:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "specialized-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([331, 301]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "speaking-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "out\n",
       "1      343\n",
       "0      289\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "engaged-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50       331\n",
      "           1       0.48      0.55      0.52       301\n",
      "\n",
      "    accuracy                           0.51       632\n",
      "   macro avg       0.51      0.51      0.51       632\n",
      "weighted avg       0.51      0.51      0.51       632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "organized-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5063291139240507"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(results,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "senior-plumbing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[165:175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "virgin-track",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            out\n",
       "date           \n",
       "2019-06-20    0\n",
       "2019-06-21    0\n",
       "2019-06-24    0\n",
       "2019-06-25    1\n",
       "2019-06-26    1\n",
       "2019-06-27    1\n",
       "2019-06-28    1\n",
       "2019-07-01    1\n",
       "2019-07-02    1\n",
       "2019-07-03    1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[165:175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superior-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def boolean_string(s):\n",
    "    if s not in {'False', 'True'}:\n",
    "        raise ValueError('Not a valid boolean string')\n",
    "    return s == 'True'\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def loaddata(filename):\n",
    "    df = pd.read_csv(filename, header=None, delimiter=\",\")\n",
    "    a = np.array(df.as_matrix())\n",
    "    return a\n",
    "\n",
    "\n",
    "def load_raw_ts(path, dataset, tensor_format=True):\n",
    "    path = path + \"raw/\" + dataset + \"/\"\n",
    "    x_train = np.load(path + 'X_train.npy')\n",
    "    y_train = np.load(path + 'y_train.npy')\n",
    "    x_test = np.load(path + 'X_test.npy')\n",
    "    y_test = np.load(path + 'y_test.npy')\n",
    "    ts = np.concatenate((x_train, x_test), axis=0)\n",
    "    ts = np.transpose(ts, axes=(0, 2, 1))\n",
    "    labels = np.concatenate((y_train, y_test), axis=0)\n",
    "    nclass = int(np.amax(labels)) + 1\n",
    "\n",
    "\n",
    "    train_size = y_train.shape[0]\n",
    "\n",
    "    total_size = labels.shape[0]\n",
    "    idx_train = range(train_size)\n",
    "    idx_val = range(train_size, total_size)\n",
    "    idx_test = range(train_size, total_size)\n",
    "\n",
    "    if tensor_format:\n",
    "        # features = torch.FloatTensor(np.array(features))\n",
    "        ts = torch.FloatTensor(np.array(ts))\n",
    "        labels = torch.LongTensor(labels)\n",
    "\n",
    "        idx_train = torch.LongTensor(idx_train)\n",
    "        idx_val = torch.LongTensor(idx_val)\n",
    "        idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return ts, labels, idx_train, idx_val, idx_test, nclass\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    row_sums = mx.sum(axis=1)\n",
    "    mx = mx.astype('float32')\n",
    "    row_sums_inverse = 1 / row_sums\n",
    "    f = mx.multiply(row_sums_inverse)\n",
    "    return sp.csr_matrix(f).astype('float32')\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    accuracy_score = (sklearn.metrics.accuracy_score(labels, preds))\n",
    "\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "\n",
    "def output_conv_size(in_size, kernel_size, stride, padding):\n",
    "\n",
    "    output = int((in_size - kernel_size + 2 * padding) / stride) + 1\n",
    "\n",
    "    return output\n",
    "\n",
    "def dump_embedding(proto_embed, sample_embed, labels, dump_file='/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/embeddings.txt'):\n",
    "    proto_embed = proto_embed.cpu().detach().numpy()\n",
    "    sample_embed = sample_embed.cpu().detach().numpy()\n",
    "    embed = np.concatenate((proto_embed, sample_embed), axis=0)\n",
    "\n",
    "    nclass = proto_embed.shape[0]\n",
    "    labels = np.concatenate((np.asarray([i for i in range(nclass)]),\n",
    "                             labels.squeeze().cpu().detach().numpy()), axis=0)\n",
    "\n",
    "    with open(dump_file, 'w') as f:\n",
    "        for i in range(len(embed)):\n",
    "            label = str(labels[i])\n",
    "            line = label + \",\" + \",\".join([\"%.4f\" % j for j in embed[i].tolist()])\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-cherry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affiliated-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from utils import euclidean_dist, normalize, output_conv_size, dump_embedding\n",
    "import numpy as np\n",
    "\n",
    "class TapNet(nn.Module):\n",
    "\n",
    "    def __init__(self,input_data, nfeat, len_ts, nclass, dropout, filters, kernels, dilation, layers, use_rp, rp_params,\n",
    "                 use_att=True, use_metric=False, use_lstm=False, use_cnn=True, lstm_dim=128):\n",
    "        super(TapNet, self).__init__()\n",
    "        self.nclass = nclass\n",
    "        self.dropout = dropout\n",
    "        self.use_metric = use_metric\n",
    "        self.use_lstm = use_lstm\n",
    "        self.use_cnn = use_cnn\n",
    "\n",
    "        # parameters for random projection\n",
    "        self.use_rp = use_rp\n",
    "        self.rp_group, self.rp_dim = rp_params\n",
    "\n",
    "        if True:\n",
    "            # LSTM\n",
    "            self.channel = nfeat\n",
    "            self.ts_length = len_ts\n",
    "\n",
    "            self.lstm_dim = lstm_dim\n",
    "            self.lstm = nn.LSTM(self.ts_length, self.lstm_dim)\n",
    "\n",
    "            paddings = [0, 0, 0]\n",
    "            if self.use_rp:\n",
    "                self.conv_1_models = nn.ModuleList()\n",
    "                self.idx = []\n",
    "                for i in range(self.rp_group):\n",
    "                    self.conv_1_models.append(nn.Conv1d(self.rp_dim, filters[0], kernel_size=kernels[0], dilation=dilation, stride=1, padding=paddings[0]))\n",
    "                    self.idx.append(np.random.permutation(nfeat)[0: self.rp_dim])\n",
    "            else:\n",
    "                self.conv_1 = nn.Conv1d(self.channel, filters[0], kernel_size=kernels[0], dilation=dilation, stride=1, padding=paddings[0])\n",
    "\n",
    "            self.conv_bn_1 = nn.BatchNorm1d(filters[0])\n",
    "\n",
    "            self.conv_2 = nn.Conv1d(filters[0], filters[1], kernel_size=kernels[1], stride=1, padding=paddings[1])\n",
    "\n",
    "            self.conv_bn_2 = nn.BatchNorm1d(filters[1])\n",
    "\n",
    "            self.conv_3 = nn.Conv1d(filters[1], filters[2], kernel_size=kernels[2], stride=1, padding=paddings[2])\n",
    "\n",
    "            self.conv_bn_3 = nn.BatchNorm1d(filters[2])\n",
    "\n",
    "            # compute the size of input for fully connected layers\n",
    "            fc_input = 0\n",
    "            if self.use_cnn:\n",
    "                conv_size = len_ts\n",
    "                for i in range(len(filters)):\n",
    "                    conv_size = output_conv_size(conv_size, kernels[i], 1, paddings[i])\n",
    "                fc_input += conv_size \n",
    "                #* filters[-1]\n",
    "            if self.use_lstm:\n",
    "                fc_input += conv_size * self.lstm_dim\n",
    "            \n",
    "            if self.use_rp:\n",
    "                fc_input = self.rp_group * filters[2] + self.lstm_dim\n",
    "\n",
    "\n",
    "        # Representation mapping function\n",
    "        layers = [fc_input] + layers\n",
    "     #   print(\"Layers\", layers)\n",
    "        self.mapping = nn.Sequential()\n",
    "        for i in range(len(layers) - 2):\n",
    "            self.mapping.add_module(\"fc_\" + str(i), nn.Linear(layers[i], layers[i + 1]))\n",
    "            self.mapping.add_module(\"bn_\" + str(i), nn.BatchNorm1d(layers[i + 1]))\n",
    "            self.mapping.add_module(\"relu_\" + str(i), nn.LeakyReLU())\n",
    "\n",
    "        # add last layer\n",
    "        self.mapping.add_module(\"fc_\" + str(len(layers) - 2), nn.Linear(layers[-2], layers[-1]))\n",
    "        if len(layers) == 2:  # if only one layer, add batch normalization\n",
    "            self.mapping.add_module(\"bn_\" + str(len(layers) - 2), nn.BatchNorm1d(layers[-1]))\n",
    "\n",
    "        # Attention\n",
    "        att_dim, semi_att_dim = 128, 128\n",
    "        self.use_att = use_att\n",
    "        if self.use_att:\n",
    "            self.att_models = nn.ModuleList()\n",
    "            for _ in range(nclass):\n",
    "\n",
    "                att_model = nn.Sequential(\n",
    "                    nn.Linear(layers[-1], att_dim),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(att_dim, 1)\n",
    "                )\n",
    "                self.att_models.append(att_model)\n",
    "\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        x, labels, idx_train, idx_val, idx_test = input_data  # x is N * L, where L is the time-series feature dimension\n",
    "\n",
    "        if True:\n",
    "            N = x.size(0)\n",
    "\n",
    "            # LSTM\n",
    "            if self.use_lstm:\n",
    "                x_lstm = self.lstm(x)[0]\n",
    "                x_lstm = x_lstm.mean(1)\n",
    "                x_lstm = x_lstm.view(N, -1)\n",
    "\n",
    "            if self.use_cnn:\n",
    "                # Covolutional Network\n",
    "                # input ts: # N * C * L\n",
    "                if self.use_rp:\n",
    "                    for i in range(len(self.conv_1_models)):\n",
    "                        #x_conv = x\n",
    "                        x_conv = self.conv_1_models[i](x[:, self.idx[i], :])\n",
    "                        x_conv = self.conv_bn_1(x_conv)\n",
    "                        x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                        x_conv = self.conv_2(x_conv)\n",
    "                        x_conv = self.conv_bn_2(x_conv)\n",
    "                        x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                        x_conv = self.conv_3(x_conv)\n",
    "                        x_conv = self.conv_bn_3(x_conv)\n",
    "                        x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                        x_conv = torch.mean(x_conv, 2)\n",
    "\n",
    "                        if i == 0:\n",
    "                            x_conv_sum = x_conv\n",
    "                        else:\n",
    "                            x_conv_sum = torch.cat([x_conv_sum, x_conv], dim=1)\n",
    "                    x_conv = x_conv_sum\n",
    "                else:\n",
    "                    x_conv = x\n",
    "                    x_conv = self.conv_1(x_conv)  # N * C * L\n",
    "                    x_conv = self.conv_bn_1(x_conv)\n",
    "                    x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                    x_conv = self.conv_2(x_conv)\n",
    "                    x_conv = self.conv_bn_2(x_conv)\n",
    "                    x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                    x_conv = self.conv_3(x_conv)\n",
    "                    x_conv = self.conv_bn_3(x_conv)\n",
    "                    x_conv = F.leaky_relu(x_conv)\n",
    "\n",
    "                    x_conv = x_conv.view(N, -1)\n",
    "\n",
    "            if self.use_lstm and self.use_cnn:\n",
    "                x = torch.cat([x_conv, x_lstm], dim=1)\n",
    "            elif self.use_lstm:\n",
    "                x = x_lstm\n",
    "            elif self.use_cnn:\n",
    "                x = x_conv\n",
    "            #\n",
    "\n",
    "        # linear mapping to low-dimensional space\n",
    "        x = self.mapping(x)\n",
    "\n",
    "        # generate the class protocal with dimension C * D (nclass * dim)\n",
    "        proto_list = []\n",
    "        for i in range(self.nclass):\n",
    "            idx = (labels[idx_train].squeeze() == i).nonzero().squeeze(1)\n",
    "            if self.use_att:\n",
    "                A = self.att_models[i](x[idx_train][idx])  # N_k * 1\n",
    "                A = torch.transpose(A, 1, 0)  # 1 * N_k\n",
    "                A = F.softmax(A, dim=1)  # softmax over N_k\n",
    "\n",
    "                class_repr = torch.mm(A, x[idx_train][idx]) # 1 * L\n",
    "                class_repr = torch.transpose(class_repr, 1, 0)  # L * 1\n",
    "            else:  # if do not use attention, simply use the mean of training samples with the same labels.\n",
    "                class_repr = x[idx_train][idx].mean(0)  # L * 1\n",
    "            proto_list.append(class_repr.view(1, -1))\n",
    "        x_proto = torch.cat(proto_list, dim=0)\n",
    "\n",
    "        # prototype distance\n",
    "        proto_dists = euclidean_dist(x_proto, x_proto)\n",
    "        proto_dists = torch.exp(-0.5*proto_dists)\n",
    "        num_proto_pairs = int(self.nclass * (self.nclass - 1) / 2)\n",
    "        proto_dist = torch.sum(proto_dists) / num_proto_pairs\n",
    "\n",
    "        dists = euclidean_dist(x, x_proto)\n",
    "\n",
    "        dump_embedding(x_proto, x, labels)\n",
    "        return torch.exp(-0.5*dists), proto_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "labeled-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_data,use_metric=0.001,metric_param=0.01,stop_thres = 1e-9):\n",
    "    loss_list = [sys.maxsize]\n",
    "    test_best_possible, best_so_far = 0.0, sys.maxsize\n",
    "    for epoch in range(3000):\n",
    "\n",
    "        t = time.time()\n",
    "        tapnet.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, proto_dist = tapnet(input_data)\n",
    "\n",
    "        loss_train = F.cross_entropy(output[idx_train], torch.squeeze(labels[idx_train]))\n",
    "        if use_metric:\n",
    "            loss_train = loss_train + metric_param * proto_dist\n",
    "\n",
    "        if abs(loss_train.item() - loss_list[-1]) < stop_thres \\\n",
    "                or loss_train.item() > loss_list[-1]:\n",
    "            break\n",
    "        else:\n",
    "            loss_list.append(loss_train.item())\n",
    "\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = F.cross_entropy(output[idx_val], torch.squeeze(labels[idx_val]))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "\n",
    "        \"\"\"print('Epoch: {:04d}'.format(epoch + 1),\n",
    "              'loss_train: {:.8f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\"\"\"\n",
    "\n",
    "        if acc_val.item() > test_best_possible:\n",
    "            test_best_possible = acc_val.item()\n",
    "        if best_so_far > loss_train.item():\n",
    "            best_so_far = loss_train.item()\n",
    "            test_acc = acc_val.item()\n",
    "    #(\"test_acc: \" + str(test_acc)),(\"best possible: \" + str(test_best_possible))\n",
    "    return round(test_acc,3), round(test_best_possible,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infectious-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, idx_train, idx_val, idx_test, nclass = load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\", dataset = 'ArticularyWordRecognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"ArticularyWordRecognition\",\"AtrialFibrilation\",\"BasicMotions\",\n",
    "\"CharacterTrajectories\",\"Cricket\",\"DuckDuckGeese\",\"EigenWorms\",\"Epilepsy\",\"ERing\",\"EthanolConcentration\",\n",
    "\"FaceDetection\",\"FingerMovements\",\"HandMovementDirection\",\"Handwriting\",\"Heartbeat\",\"InsectWingbeat\",\n",
    "\"JapaneseVowels\",\"Libras\",\"LSST\",\"MotorImagery\",\"NATOPS\",\"PEMS-SF\",\"PenDigits\",\"Phoneme\",\"RacketSports\",\n",
    "\"SelfRegulationSCP1\",\"SelfRegulationSCP2\",\"SpokenArabicDigits\",\"StandWalkJump\",\"UWaveGestureLibrary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "neural-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"ArticularyWordRecognition\",\"BasicMotions\",\n",
    "\"CharacterTrajectories\",\"Cricket\",\"DuckDuckGeese\",\"EigenWorms\",\"Epilepsy\",\"ERing\",\"EthanolConcentration\",\n",
    "\"FaceDetection\",\"FingerMovements\",\"HandMovementDirection\",\"Handwriting\",\"Heartbeat\",\"InsectWingbeat\",\"Libras\",\"LSST\",\"MotorImagery\",\"NATOPS\",\"PEMS-SF\",\"Phoneme\",\"RacketSports\",\n",
    "\"SelfRegulationSCP1\",\"SelfRegulationSCP2\",\"SpokenArabicDigits\",\"StandWalkJump\",\"UWaveGestureLibrary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prerequisite-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['ArticularyWordRecognition','BasicMotions','CharacterTrajectories','FaceDetection','HandMovementDirection',\n",
    "'Heartbeat','MotorImagery','NATOPS','PEMS-SF','Phoneme','SelfRegulationSCP2','SpokenArabicDigits','StandWalkJump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outside-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in files:\n",
    "    features, labels, idx_train, idx_val, idx_test, nclass = \\\n",
    "                    load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\",\n",
    "                                                                      dataset = dataset)\n",
    "    #print(dataset)\n",
    "    #print(features.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assumed-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "burning-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(tapnet.parameters(),\n",
    "                      lr=1e-5, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "protected-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack as vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cosmetic-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [np.array(['Dataset','Test_acc','Best_acc', 'Time'])]\n",
    "for dataset in files:\n",
    "        features, labels, idx_train, idx_val, idx_test, nclass = \\\n",
    "                        load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\",\n",
    "                                                                      dataset = dataset)\n",
    "    \n",
    "        input_data = features, labels, idx_train, idx_val, idx_test\n",
    "    \n",
    "\n",
    "        tapnet = TapNet(input_data = input_data,\n",
    "                   nfeat=features.shape[1],\n",
    "                   len_ts=features.shape[2],\n",
    "                   layers=[500,300],\n",
    "                   nclass=nclass,\n",
    "                   dropout=0.5,\n",
    "                   use_lstm=True,\n",
    "                   use_cnn=True,\n",
    "                   filters=(256,256,128),\n",
    "                   dilation=1,\n",
    "                   kernels=(8,5,3),\n",
    "                   use_metric=0.001,\n",
    "                   use_rp=True,\n",
    "                   rp_params=(1,3),\n",
    "                   lstm_dim=128)\n",
    "\n",
    "        start = time.time()\n",
    "        reults = train(input_data)\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        res = np.array([dataset,reults[0],reults[1], total_time])\n",
    "        list_.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "frank-interface",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Test_acc</th>\n",
       "      <th>Best_acc</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArticularyWordRecognition</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.847</td>\n",
       "      <td>8.398931980133057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BasicMotions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8341081142425537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CharacterTrajectories</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.971</td>\n",
       "      <td>57.23926401138306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FaceDetection</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.517</td>\n",
       "      <td>193.37761187553406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HandMovementDirection</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>9.212671041488647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heartbeat</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.732</td>\n",
       "      <td>17.573044061660767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MotorImagery</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>141.26107907295227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NATOPS</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.661</td>\n",
       "      <td>2.132493019104004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PEMS-SF</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>20.480066061019897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Phoneme</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>179.22083711624146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SelfRegulationSCP2</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>43.77568316459656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SpokenArabicDigits</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.633</td>\n",
       "      <td>91.3661949634552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>StandWalkJump</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.067</td>\n",
       "      <td>6.435902118682861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Dataset Test_acc Best_acc                Time\n",
       "0   ArticularyWordRecognition    0.847    0.847   8.398931980133057\n",
       "1                BasicMotions      1.0      1.0  0.8341081142425537\n",
       "2       CharacterTrajectories    0.971    0.971   57.23926401138306\n",
       "3               FaceDetection    0.517    0.517  193.37761187553406\n",
       "4       HandMovementDirection    0.324    0.324   9.212671041488647\n",
       "5                   Heartbeat    0.732    0.732  17.573044061660767\n",
       "6                MotorImagery     0.59     0.59  141.26107907295227\n",
       "7                      NATOPS    0.661    0.661   2.132493019104004\n",
       "8                     PEMS-SF    0.324    0.324  20.480066061019897\n",
       "9                     Phoneme    0.126    0.126  179.22083711624146\n",
       "10         SelfRegulationSCP2    0.533    0.533   43.77568316459656\n",
       "11         SpokenArabicDigits    0.633    0.633    91.3661949634552\n",
       "12              StandWalkJump    0.067    0.067   6.435902118682861"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list_[1:],columns=list_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "amino-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[575, 9, 144]\n",
      "[80, 6, 100]\n",
      "[2858, 3, 182]\n",
      "[9414, 62, 144]\n",
      "[234, 10, 400]\n",
      "[409, 61, 405]\n",
      "[378, 64, 3000]\n",
      "[360, 24, 51]\n",
      "[440, 963, 144]\n",
      "[6668, 11, 217]\n",
      "[380, 7, 1152]\n",
      "[8798, 13, 93]\n",
      "[27, 4, 2500]\n"
     ]
    }
   ],
   "source": [
    "for dataset in files:\n",
    "        features, labels, idx_train, idx_val, idx_test, nclass = \\\n",
    "                        load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\",\n",
    "                                                                      dataset = dataset)\n",
    "        print([features.size()[0],features.size()[1],features.size()[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "typical-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "hungry-beauty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 24,  5])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((3,4,56))\n",
    "np.array((13,24,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "extreme-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(datatset, use_metric = 0.001, metric_param = 0.01):\n",
    "    features, labels, idx_train, idx_val, idx_test, nclass = \\\n",
    "                        load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\",\n",
    "                                                                      dataset = dataset)\n",
    "    \n",
    "    input_data = features, labels, idx_train, idx_val, idx_test\n",
    "    \n",
    "    tapnet = TapNet(input_data = input_data,\n",
    "                   nfeat=features.shape[1],\n",
    "                   len_ts=features.shape[2],\n",
    "                   layers=[500,300],\n",
    "                   nclass=nclass,\n",
    "                   dropout=0.5,\n",
    "                   use_lstm=True,\n",
    "                   use_cnn=True,\n",
    "                   filters=(256,256,128),\n",
    "                   dilation=1,\n",
    "                   kernels=(8,5,3),\n",
    "                   use_metric=0.001,\n",
    "                   use_rp=True,\n",
    "                   rp_params=(1,3),\n",
    "                   lstm_dim=128)\n",
    "    \n",
    "    output, proto_dist = tapnet(input_data)\n",
    "    loss_test = F.cross_entropy(output[idx_test], torch.squeeze(labels[idx_test]))\n",
    "    if use_metric:\n",
    "        loss_test = loss_test - metric_param * proto_dist\n",
    "\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "        print(dataset, \"Test set results:\",\n",
    "              \"loss= {:.4f}\".format(loss_test.item()),\n",
    "              \"accuracy= {:.4f}\".format(acc_test.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "verified-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticularyWordRecognition Test set results: loss= 3.2076 accuracy= 0.8600\n",
      "BasicMotions Test set results: loss= 1.3051 accuracy= 1.0000\n",
      "CharacterTrajectories Test set results: loss= 2.9576 accuracy= 0.9680\n",
      "FaceDetection Test set results: loss= 0.6534 accuracy= 0.5434\n",
      "HandMovementDirection Test set results: loss= 1.3754 accuracy= 0.4054\n",
      "Heartbeat Test set results: loss= 0.6662 accuracy= 0.5512\n",
      "MotorImagery Test set results: loss= 0.6564 accuracy= 0.4000\n",
      "NATOPS Test set results: loss= 1.7851 accuracy= 0.6556\n",
      "PEMS-SF Test set results: loss= 1.9383 accuracy= 0.3584\n",
      "Phoneme Test set results: loss= 3.6590 accuracy= 0.1265\n",
      "SelfRegulationSCP2 Test set results: loss= 0.6622 accuracy= 0.5722\n",
      "SpokenArabicDigits Test set results: loss= 2.2981 accuracy= 0.6016\n",
      "StandWalkJump Test set results: loss= 1.0886 accuracy= 0.3333\n"
     ]
    }
   ],
   "source": [
    "for dataset in files:\n",
    "    test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-lottery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-rubber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-abraham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interim-bidder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsai in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (0.2.18)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (1.9.0)\n",
      "Requirement already satisfied: dask>=2021.3.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (2021.8.1)\n",
      "Collecting argparse>=1.4.0\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (1.1.1)\n",
      "Requirement already satisfied: pyts>=0.11.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (1.7.1)\n",
      "Requirement already satisfied: torch-optimizer>=0.1.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.1.0)\n",
      "Requirement already satisfied: sktime>=0.6.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.7.0)\n",
      "Requirement already satisfied: packaging in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (21.0)\n",
      "Requirement already satisfied: pip in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (21.0.1)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.12.2)\n",
      "Requirement already satisfied: tsfresh>=0.18.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.18.0)\n",
      "Requirement already satisfied: fastai>=2.4.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (2.5.2)\n",
      "Requirement already satisfied: pyunpack>=0.2.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.2.2)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.8.0)\n",
      "Requirement already satisfied: numba>=0.53.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsai) (0.53.1)\n",
      "Requirement already satisfied: pyyaml in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from dask>=2021.3.0->tsai) (5.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from dask>=2021.3.0->tsai) (2021.7.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from dask>=2021.3.0->tsai) (0.11.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from dask>=2021.3.0->tsai) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from dask>=2021.3.0->tsai) (1.6.0)\n",
      "Requirement already satisfied: pillow>6.0.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (8.3.1)\n",
      "Requirement already satisfied: requests in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (2.26.0)\n",
      "Requirement already satisfied: matplotlib in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (3.4.2)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (1.3.26)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (0.10.0)\n",
      "Requirement already satisfied: pandas in /Users/abhijitdeshpande/.local/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (1.2.2)\n",
      "Requirement already satisfied: spacy<4 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (3.1.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (0.0.5)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastai>=2.4.0->tsai) (1.0.0)\n",
      "Requirement already satisfied: numpy in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from fastprogress>=0.2.4->fastai>=2.4.0->tsai) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from imbalanced-learn>=0.8.0->tsai) (1.0.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from numba>=0.53.1->tsai) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from numba>=0.53.1->tsai) (58.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from packaging->tsai) (2.4.7)\n",
      "Requirement already satisfied: locket in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/locket-0.2.1-py3.7.egg (from partd>=0.3.10->dask>=2021.3.0->tsai) (0.2.1)\n",
      "Requirement already satisfied: easyprocess in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from pyunpack>=0.2.2->tsai) (0.3)\n",
      "Requirement already satisfied: entrypoint2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from pyunpack>=0.2.2->tsai) (0.2.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from scikit-learn>=0.24.2->tsai) (2.1.0)\n",
      "Requirement already satisfied: wheel in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from sktime>=0.6.1->tsai) (0.37.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from pandas->fastai>=2.4.0->tsai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from pandas->fastai>=2.4.0->tsai) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->fastai>=2.4.0->tsai) (1.15.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (3.0.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (2.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (0.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (3.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (4.62.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (3.10.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (8.0.8)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from spacy<4->fastai>=2.4.0->tsai) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.4->spacy<4->fastai>=2.4.0->tsai) (3.5.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai>=2.4.0->tsai) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from requests->fastai>=2.4.0->tsai) (2.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from requests->fastai>=2.4.0->tsai) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from requests->fastai>=2.4.0->tsai) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from requests->fastai>=2.4.0->tsai) (1.26.6)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from statsmodels>=0.12.2->tsai) (0.5.1)\n",
      "Requirement already satisfied: pytorch-ranger>=0.1.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from torch-optimizer>=0.1.0->tsai) (0.1.1)\n",
      "Collecting distributed>=2.11.0\n",
      "  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 786 kB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matrixprofile>=1.1.10<2.0.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsfresh>=0.18.0->tsai) (1.1.10)\n",
      "Requirement already satisfied: stumpy>=1.7.2 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from tsfresh>=0.18.0->tsai) (1.9.2)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tornado>=5 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from distributed>=2.11.0->tsfresh>=0.18.0->tsai) (6.1)\n",
      "Collecting distributed>=2.11.0\n",
      "  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 779 kB 21.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778 kB 23.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from distributed>=2.11.0->tsfresh>=0.18.0->tsai) (5.8.0)\n",
      "Collecting click>=6.6\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-macosx_10_14_x86_64.whl (72 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from click>=6.6->distributed>=2.11.0->tsfresh>=0.18.0->tsai) (4.8.1)\n",
      "Collecting protobuf==3.11.2\n",
      "  Using cached protobuf-3.11.2-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from matplotlib->fastai>=2.4.0->tsai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from matplotlib->fastai>=2.4.0->tsai) (1.3.1)\n",
      "Collecting click>=6.6\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82 kB 6.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abhijitdeshpande/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages (from jinja2->spacy<4->fastai>=2.4.0->tsai) (2.0.1)\n",
      "Installing collected packages: click, heapdict, zict, tblib, sortedcontainers, protobuf, msgpack, distributed, argparse\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.2\n",
      "    Uninstalling protobuf-3.17.2:\n",
      "      Successfully uninstalled protobuf-3.17.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 3.2.1 which is incompatible.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.20.3 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed argparse-1.4.0 click-7.1.2 distributed-2021.8.1 heapdict-1.0.1 msgpack-1.0.2 protobuf-3.11.2 sortedcontainers-2.4.0 tblib-1.7.0 zict-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formed-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medium-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.imports import *\n",
    "#from tsai.data.external import *\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automated-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV, RidgeCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "french-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is an unofficial ROCKET implementation in Pytorch developed by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "# Angus Dempster, Francois Petitjean, Geoff Webb\n",
    "# Dempster A, Petitjean F, Webb GI (2019) ROCKET: Exceptionally fast and\n",
    "# accurate time series classification using random convolutional kernels.\n",
    "# arXiv:1910.13051\n",
    "# Official repo: https://github.com/angus924/rocket\n",
    "\n",
    "# changes: \n",
    "# - added kss parameter to generate_kernels\n",
    "# - convert X to np.float64\n",
    "\n",
    "def generate_kernels(input_length, num_kernels, kss=[7, 9, 11], pad=True, dilate=True):\n",
    "    candidate_lengths = np.array((kss))\n",
    "    # initialise kernel parameters\n",
    "    weights = np.zeros((num_kernels, candidate_lengths.max())) # see note\n",
    "    lengths = np.zeros(num_kernels, dtype = np.int32) # see note\n",
    "    biases = np.zeros(num_kernels)\n",
    "    dilations = np.zeros(num_kernels, dtype = np.int32)\n",
    "    paddings = np.zeros(num_kernels, dtype = np.int32)\n",
    "    # note: only the first *lengths[i]* values of *weights[i]* are used\n",
    "    for i in range(num_kernels):\n",
    "        length = np.random.choice(candidate_lengths)\n",
    "        _weights = np.random.normal(0, 1, length)\n",
    "        bias = np.random.uniform(-1, 1)\n",
    "        if dilate: dilation = 2 ** np.random.uniform(0, np.log2((input_length - 1) // (length - 1)))\n",
    "        else: dilation = 1\n",
    "        if pad: padding = ((length - 1) * dilation) // 2 if np.random.randint(2) == 1 else 0\n",
    "        else: padding = 0\n",
    "        weights[i, :length] = _weights - _weights.mean()\n",
    "        lengths[i], biases[i], dilations[i], paddings[i] = length, bias, dilation, padding\n",
    "    return weights, lengths, biases, dilations, paddings\n",
    "\n",
    "@njit(fastmath = True)\n",
    "def apply_kernel(X, weights, length, bias, dilation, padding):\n",
    "    # zero padding\n",
    "    if padding > 0:\n",
    "        _input_length = len(X)\n",
    "        _X = np.zeros(_input_length + (2 * padding))\n",
    "        _X[padding:(padding + _input_length)] = X\n",
    "        X = _X\n",
    "    input_length = len(X)\n",
    "    output_length = input_length - ((length - 1) * dilation)\n",
    "    _ppv = 0 # \"proportion of positive values\"\n",
    "    _max = np.NINF\n",
    "    for i in range(output_length):\n",
    "        _sum = bias\n",
    "        for j in range(length):\n",
    "            _sum += weights[j] * X[i + (j * dilation)]\n",
    "        if _sum > 0:\n",
    "            _ppv += 1\n",
    "        if _sum > _max:\n",
    "            _max = _sum\n",
    "    return _ppv / output_length, _max\n",
    "\n",
    "@njit(parallel = True, fastmath = True)\n",
    "def apply_kernels(X, kernels):\n",
    "    X = X.astype(np.float64)\n",
    "    weights, lengths, biases, dilations, paddings = kernels\n",
    "    num_examples = len(X)\n",
    "    num_kernels = len(weights)\n",
    "    # initialise output\n",
    "    _X = np.zeros((num_examples, num_kernels * 2)) # 2 features per kernel\n",
    "    for i in prange(num_examples):\n",
    "        for j in range(num_kernels):\n",
    "            _X[i, (j * 2):((j * 2) + 2)] = \\\n",
    "            apply_kernel(X[i], weights[j][:lengths[j]], lengths[j], biases[j], dilations[j], paddings[j])\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "objective-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class ROCKET(nn.Module):\n",
    "    \"\"\"RandOm Convolutional KErnel Transform\n",
    "    ROCKET is a GPU Pytorch implementation of the ROCKET functions generate_kernels\n",
    "    and apply_kernels that can be used  with univariate and multivariate time series.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_in, seq_len, n_kernels=10_000, kss=[7, 9, 11], device=None, verbose=False):\n",
    "\n",
    "        '''\n",
    "        Input: is a 3d torch tensor of type torch.float32. When used with univariate TS,\n",
    "        make sure you transform the 2d to 3d by adding unsqueeze(1).\n",
    "        c_in: number of channels or features. For univariate c_in is 1.\n",
    "        seq_len: sequence length\n",
    "        '''\n",
    "        super().__init__()\n",
    "        device = ifnone(device, default_device())\n",
    "        kss = [ks for ks in kss if ks < seq_len]\n",
    "        convs = nn.ModuleList()\n",
    "        for i in range(n_kernels):\n",
    "            ks = np.random.choice(kss)\n",
    "            dilation = 2**np.random.uniform(0, np.log2((seq_len - 1) // (ks - 1)))\n",
    "            padding = int((ks - 1) * dilation // 2) if np.random.randint(2) == 1 else 0\n",
    "            weight = torch.randn(1, c_in, ks)\n",
    "            weight -= weight.mean()\n",
    "            bias = 2 * (torch.rand(1) - .5)\n",
    "            layer = nn.Conv1d(c_in, 1, ks, padding=2 * padding, dilation=int(dilation), bias=True)\n",
    "            layer.weight = torch.nn.Parameter(weight, requires_grad=False)\n",
    "            layer.bias = torch.nn.Parameter(bias, requires_grad=False)\n",
    "            convs.append(layer)\n",
    "        self.convs = convs\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kss = kss\n",
    "        self.to(device=device)\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def forward(self, x):\n",
    "        _output = []\n",
    "        for i in progress_bar(range(self.n_kernels), display=self.verbose, leave=False, comment='kernel/kernels'):\n",
    "            out = self.convs[i](x).cpu()\n",
    "            _max = out.max(dim=-1)[0]\n",
    "            _ppv = torch.gt(out, 0).sum(dim=-1).float() / out.shape[-1]\n",
    "            _output.append(_max)\n",
    "            _output.append(_ppv)\n",
    "        return torch.cat(_output, dim=1)\n",
    "\n",
    "# Cell\n",
    "def create_rocket_features(dl, model, verbose=False):\n",
    "    \"\"\"Args:\n",
    "        model     : ROCKET model instance\n",
    "        dl        : single TSDataLoader (for example dls.train or dls.valid)\n",
    "    \"\"\"\n",
    "    _x_out = []\n",
    "    _y_out = []\n",
    "    for i,(xb,yb) in enumerate(progress_bar(dl, display=verbose, leave=False, comment='batch/batches')):\n",
    "        _x_out.append(model(xb).cpu())\n",
    "        _y_out.append(yb.cpu())\n",
    "    return torch.cat(_x_out).numpy(), torch.cat(_y_out).numpy()\n",
    "\n",
    "get_rocket_features = create_rocket_features\n",
    "\n",
    "# Cell\n",
    "class RocketClassifier(sklearn.pipeline.Pipeline):\n",
    "    \"\"\"Time series classification using ROCKET features and a linear classifier\"\"\"\n",
    "\n",
    "    def __init__(self, num_kernels=10_000, normalize_input=True, random_state=None,\n",
    "                 alphas=np.logspace(-3, 3, 7), normalize_features=True, memory=None, verbose=False, scoring=None, class_weight=None, **kwargs):\n",
    "        \"\"\"\n",
    "        RocketClassifier is recommended for up to 10k time series.\n",
    "        For a larger dataset, you can use ROCKET (in Pytorch).\n",
    "        scoring = None --> defaults to accuracy.\n",
    "        Rocket args:\n",
    "            num_kernels     : int, number of random convolutional kernels (default 10,000)\n",
    "            normalize_input : boolean, whether or not to normalise the input time series per instance (default True)\n",
    "            random_state    : int (ignored unless int due to compatability with Numba), random seed (optional, default None)\n",
    "        \"\"\"\n",
    "        self.steps = [('rocket', Rocket(num_kernels=num_kernels, normalise=normalize_input, random_state=random_state)),\n",
    "                      ('ridgeclassifiercv', RidgeClassifierCV(alphas=alphas, normalize=normalize_features, scoring=scoring,\n",
    "                                                              class_weight=class_weight, **kwargs))]\n",
    "        store_attr()\n",
    "        self._validate_steps()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Pipeline(steps={self.steps.copy()})'\n",
    "\n",
    "    def save(self, fname='Rocket', path='./models'):\n",
    "        path = Path(path)\n",
    "        filename = path/fname\n",
    "        with open(f'{filename}.pkl', 'wb') as output:\n",
    "            pickle.dump(self, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Cell\n",
    "def load_rocket(fname='Rocket', path='./models'):\n",
    "    path = Path(path)\n",
    "    filename = path/fname\n",
    "    with open(f'{filename}.pkl', 'rb') as input:\n",
    "        output = pickle.load(input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "growing-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = RocketClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "successful-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.external import *\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import tempfile\n",
    "try: from urllib import urlretrieve\n",
    "except ImportError: from urllib.request import urlretrieve\n",
    "import shutil\n",
    "from pyunpack import Archive\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sktime.utils.validation.panel import check_X\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe as ts2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "elder-dakota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArticularyWordRecognition',\n",
       " 'BasicMotions',\n",
       " 'FaceDetection',\n",
       " 'HandMovementDirection',\n",
       " 'Heartbeat',\n",
       " 'MotorImagery',\n",
       " 'NATOPS',\n",
       " 'PEMS-SF',\n",
       " 'SelfRegulationSCP2',\n",
       " 'StandWalkJump']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "planned-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [np.array(['Dataset','Test_acc','Time'])]\n",
    "\n",
    "for data_set in files:\n",
    "        a, b = ts2df('/Users/abhijitdeshpande/Documents/Thesis/Multivariate2018_ts/Multivariate_ts/'+data_set+'/'+data_set+'_TRAIN.ts')\n",
    "        a_test, b_test = ts2df('/Users/abhijitdeshpande/Documents/Thesis/Multivariate2018_ts/Multivariate_ts/'+data_set+'/'+data_set+'_TEST.ts')\n",
    "        \n",
    "        start = time.time()\n",
    "        cls.fit(a,b)\n",
    "        end = time.time()\n",
    "        reults = cls.score(a_test,b_test)\n",
    "        total_time = end - start\n",
    "        res = np.array([data_set,reults, total_time])\n",
    "        list_.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "manual-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dataset', 'Test_acc', 'Time'], dtype='<U8')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "middle-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Test_acc</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArticularyWordRecognition</td>\n",
       "      <td>0.9933333333333333</td>\n",
       "      <td>8.714571952819824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BasicMotions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8447060585021973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FaceDetection</td>\n",
       "      <td>0.6472758229284904</td>\n",
       "      <td>124.93500709533691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HandMovementDirection</td>\n",
       "      <td>0.5135135135135135</td>\n",
       "      <td>14.546158075332642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heartbeat</td>\n",
       "      <td>0.7707317073170732</td>\n",
       "      <td>19.483545064926147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MotorImagery</td>\n",
       "      <td>0.57</td>\n",
       "      <td>205.54224109649658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NATOPS</td>\n",
       "      <td>0.8722222222222222</td>\n",
       "      <td>2.277039051055908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PEMS-SF</td>\n",
       "      <td>0.815028901734104</td>\n",
       "      <td>12.632164239883423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SelfRegulationSCP2</td>\n",
       "      <td>0.5555555555555556</td>\n",
       "      <td>46.25992822647095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StandWalkJump</td>\n",
       "      <td>0.5333333333333333</td>\n",
       "      <td>303.01538014411926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Dataset            Test_acc                Time\n",
       "0  ArticularyWordRecognition  0.9933333333333333   8.714571952819824\n",
       "1               BasicMotions                 1.0  0.8447060585021973\n",
       "2              FaceDetection  0.6472758229284904  124.93500709533691\n",
       "3      HandMovementDirection  0.5135135135135135  14.546158075332642\n",
       "4                  Heartbeat  0.7707317073170732  19.483545064926147\n",
       "5               MotorImagery                0.57  205.54224109649658\n",
       "6                     NATOPS  0.8722222222222222   2.277039051055908\n",
       "7                    PEMS-SF   0.815028901734104  12.632164239883423\n",
       "8         SelfRegulationSCP2  0.5555555555555556   46.25992822647095\n",
       "9              StandWalkJump  0.5333333333333333  303.01538014411926"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list_[1:],columns=['Dataset','Test_acc','Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "common-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = ts2df('/Users/abhijitdeshpande/Documents/Thesis/Multivariate2018_ts/Multivariate_ts/FaceDetection/FaceDetection_TRAIN.ts')\n",
    "a_test, b_test = ts2df('/Users/abhijitdeshpande/Documents/Thesis/Multivariate2018_ts/Multivariate_ts/FaceDetection/FaceDetection_TEST.ts')\n",
    "    \n",
    "#cls.fit(a, b)\n",
    "#cls.score(a_test, b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-advance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "previous-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rocket', Rocket()), ('ridgeclassifiercv', RidgeClassifierCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                  normalize=True))])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confident-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe as ts2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "filled-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-desire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "virtual-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rocket', Rocket()), ('ridgeclassifiercv', RidgeClassifierCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                  normalize=True))])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "associate-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6563564131668559\n"
     ]
    }
   ],
   "source": [
    "#cls.save(fname)\n",
    "#del cls\n",
    "#cls = load_rocket(fname)\n",
    "print(cls.score(a_test, b_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "suburban-intranet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5890, 144)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "continuing-explorer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'progress_bar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-92dbcc6ce57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_valid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mX_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# stack arrays even if they have different lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'progress_bar' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_ = []\n",
    "X_valid_ = []\n",
    "for i in progress_bar(range(a.shape[-1]), display=True, leave=True):\n",
    "        X_train_.append((a.iloc[:,i])) # stack arrays even if they have different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-wright",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "short-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.torch_core.Module"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "roman-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Cell\n",
    "class TransformerModel(Module):\n",
    "    def __init__(self, c_in, c_out, d_model=64, n_head=1, d_ffn=128, dropout=0.1, activation=\"relu\", n_layers=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset\n",
    "            c_out: the number of target classes\n",
    "            d_model: total dimension of the model.\n",
    "            nhead:  parallel attention heads.\n",
    "            d_ffn: the dimension of the feedforward network model.\n",
    "            dropout: a Dropout layer on attn_output_weights.\n",
    "            activation: the activation function of intermediate layer, relu or gelu.\n",
    "            num_layers: the number of sub-encoder-layers in the encoder.\n",
    "        Input shape:\n",
    "            bs (batch size) x nvars (aka variables, dimensions, channels) x seq_len (aka time steps)\n",
    "            \"\"\"\n",
    "        self.permute = Permute(2, 0, 1)\n",
    "        self.inlinear = nn.Linear(c_in, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, n_head, dim_feedforward=d_ffn, dropout=dropout, activation=activation)\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, n_layers, norm=encoder_norm)\n",
    "        self.transpose = Transpose(1, 0)\n",
    "        self.max = Max(1)\n",
    "        self.outlinear = nn.Linear(d_model, c_out)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.permute(x) # bs x nvars x seq_len -> seq_len x bs x nvars\n",
    "        x = self.inlinear(x) # seq_len x bs x nvars -> seq_len x bs x d_model\n",
    "        x = self.relu(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.transpose(x) # seq_len x bs x d_model -> bs x seq_len x d_model\n",
    "        x = self.max(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.outlinear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "amber-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "nvars = 3\n",
    "seq_len = 96\n",
    "c_out = 2\n",
    "xb = torch.rand(bs, nvars, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "another-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (permute): Permute(dims=2, 0, 1)\n",
       "  (inlinear): Linear(in_features=3, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transpose): Transpose(1, 0)\n",
       "  (max): Max(dim=1, keepdim=False)\n",
       "  (outlinear): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(nvars, c_out, d_model=64, n_head=1, d_ffn=128, dropout=0.1, activation='gelu', n_layers=3)\n",
    "test_eq(model(xb).shape, [bs, c_out])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "heard-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.models.layers import *\n",
    "from tsai.models.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "portable-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class _ScaledDotProductAttention(Module):\n",
    "    def __init__(self, d_k:int): self.d_k = d_k\n",
    "    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Optional[Tensor]=None):\n",
    "\n",
    "        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        scores = torch.matmul(q, k)                                         # scores : [bs x n_heads x q_len x q_len]\n",
    "        \n",
    "        # Scale\n",
    "        scores = scores / (self.d_k ** 0.5)\n",
    "        \n",
    "        # Mask (optional)\n",
    "        if mask is not None: scores.masked_fill_(mask, -1e9)\n",
    "        \n",
    "        # SoftMax\n",
    "        attn = F.softmax(scores, dim=-1)                                    # attn   : [bs x n_heads x q_len x q_len]\n",
    "        \n",
    "        # MatMul (attn, v)\n",
    "        context = torch.matmul(attn, v)                                     # context: [bs x n_heads x q_len x d_v]\n",
    "        \n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "extensive-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class MultiHeadAttention(Module):\n",
    "    def __init__(self, d_model:int, n_heads:int, d_k:int, d_v:int):\n",
    "        r\"\"\"\n",
    "        Input shape:  Q, K, V:[batch_size (bs) x q_len x d_model], mask:[q_len x q_len]\n",
    "        \"\"\"\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        \n",
    "        self.W_O = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "\n",
    "    def forward(self, Q:Tensor, K:Tensor, V:Tensor, mask:Optional[Tensor]=None):\n",
    "        \n",
    "        bs = Q.size(0)\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        context, attn = _ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s)          # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]\n",
    "\n",
    "        # Concat\n",
    "        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # context: [bs x q_len x n_heads * d_v]\n",
    "\n",
    "        # Linear\n",
    "        output = self.W_O(context)                                                  # context: [bs x q_len x d_model]\n",
    "        \n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "located-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 50, 128]), torch.Size([16, 3, 50, 50]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "output, attn = MultiHeadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)(t, t, t)\n",
    "output.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "competent-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0858,  0.1796,  0.2057,  ...,  0.4094,  0.1129, -0.3627],\n",
       "         [-0.0844,  0.1786,  0.2056,  ...,  0.4076,  0.1131, -0.3615],\n",
       "         [-0.0850,  0.1796,  0.2054,  ...,  0.4095,  0.1135, -0.3631],\n",
       "         ...,\n",
       "         [-0.0850,  0.1787,  0.2053,  ...,  0.4084,  0.1130, -0.3619],\n",
       "         [-0.0852,  0.1796,  0.2056,  ...,  0.4091,  0.1128, -0.3626],\n",
       "         [-0.0848,  0.1786,  0.2046,  ...,  0.4079,  0.1122, -0.3614]],\n",
       "\n",
       "        [[-0.0680,  0.1790,  0.2402,  ...,  0.4153,  0.1164, -0.3363],\n",
       "         [-0.0691,  0.1790,  0.2398,  ...,  0.4158,  0.1162, -0.3362],\n",
       "         [-0.0689,  0.1797,  0.2408,  ...,  0.4156,  0.1162, -0.3356],\n",
       "         ...,\n",
       "         [-0.0680,  0.1789,  0.2396,  ...,  0.4147,  0.1160, -0.3358],\n",
       "         [-0.0685,  0.1789,  0.2399,  ...,  0.4149,  0.1161, -0.3358],\n",
       "         [-0.0681,  0.1788,  0.2398,  ...,  0.4149,  0.1167, -0.3360]],\n",
       "\n",
       "        [[-0.0867,  0.1738,  0.2386,  ...,  0.4283,  0.1146, -0.3640],\n",
       "         [-0.0873,  0.1742,  0.2388,  ...,  0.4284,  0.1149, -0.3636],\n",
       "         [-0.0866,  0.1736,  0.2386,  ...,  0.4289,  0.1148, -0.3642],\n",
       "         ...,\n",
       "         [-0.0869,  0.1738,  0.2390,  ...,  0.4280,  0.1144, -0.3634],\n",
       "         [-0.0857,  0.1731,  0.2383,  ...,  0.4288,  0.1145, -0.3642],\n",
       "         [-0.0871,  0.1742,  0.2388,  ...,  0.4284,  0.1154, -0.3633]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0496,  0.1600,  0.2321,  ...,  0.3894,  0.1011, -0.3340],\n",
       "         [-0.0496,  0.1599,  0.2320,  ...,  0.3891,  0.1013, -0.3340],\n",
       "         [-0.0490,  0.1596,  0.2315,  ...,  0.3889,  0.1019, -0.3338],\n",
       "         ...,\n",
       "         [-0.0490,  0.1593,  0.2316,  ...,  0.3888,  0.1008, -0.3335],\n",
       "         [-0.0490,  0.1597,  0.2315,  ...,  0.3895,  0.1014, -0.3340],\n",
       "         [-0.0490,  0.1597,  0.2316,  ...,  0.3897,  0.1020, -0.3343]],\n",
       "\n",
       "        [[-0.0613,  0.1705,  0.2387,  ...,  0.4392,  0.1303, -0.3413],\n",
       "         [-0.0621,  0.1711,  0.2391,  ...,  0.4399,  0.1295, -0.3416],\n",
       "         [-0.0611,  0.1699,  0.2383,  ...,  0.4388,  0.1296, -0.3413],\n",
       "         ...,\n",
       "         [-0.0626,  0.1705,  0.2387,  ...,  0.4384,  0.1310, -0.3418],\n",
       "         [-0.0623,  0.1710,  0.2381,  ...,  0.4390,  0.1301, -0.3419],\n",
       "         [-0.0617,  0.1704,  0.2385,  ...,  0.4384,  0.1304, -0.3421]],\n",
       "\n",
       "        [[-0.0729,  0.1667,  0.2266,  ...,  0.4209,  0.1057, -0.3406],\n",
       "         [-0.0728,  0.1666,  0.2267,  ...,  0.4200,  0.1065, -0.3407],\n",
       "         [-0.0728,  0.1664,  0.2262,  ...,  0.4193,  0.1057, -0.3407],\n",
       "         ...,\n",
       "         [-0.0725,  0.1661,  0.2259,  ...,  0.4197,  0.1061, -0.3414],\n",
       "         [-0.0718,  0.1654,  0.2263,  ...,  0.4192,  0.1051, -0.3399],\n",
       "         [-0.0730,  0.1667,  0.2270,  ...,  0.4204,  0.1058, -0.3406]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "subtle-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class _TSTEncoderLayer(Module):\n",
    "    def __init__(self, q_len:int, d_model:int, n_heads:int, d_k:Optional[int]=None, d_v:Optional[int]=None, d_ff:int=256, res_dropout:float=0.1, \n",
    "                 activation:str=\"gelu\"):\n",
    "\n",
    "        assert d_model // n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = ifnone(d_k, d_model // n_heads)\n",
    "        d_v = ifnone(d_v, d_model // n_heads)\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.self_attn = _MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(res_dropout)\n",
    "        self.batchnorm_attn = nn.BatchNorm1d(q_len)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), self._get_activation_fn(activation), nn.Linear(d_ff, d_model))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(res_dropout)\n",
    "        self.batchnorm_ffn = nn.BatchNorm1d(q_len)\n",
    "\n",
    "    def forward(self, src:Tensor, mask:Optional[Tensor]=None) -> Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        ## Multi-Head attention\n",
    "        src2, attn = self.self_attn(src, src, src, mask=mask)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        src = self.batchnorm_attn(src)      # Norm: batchnorm \n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        src = self.batchnorm_ffn(src) # Norm: batchnorm\n",
    "\n",
    "        return src\n",
    "\n",
    "    def _get_activation_fn(self, activation):\n",
    "        if activation == \"relu\": return nn.ReLU()\n",
    "        elif activation == \"gelu\": return nn.GELU()\n",
    "        else: return activation()\n",
    "#         raise ValueError(f'{activation} is not available. You can use \"relu\" or \"gelu\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "secondary-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 50, 128])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "output = _TSTEncoderLayer(q_len=50, d_model=128, n_heads=3, d_k=None, d_v=None, d_ff=512, res_dropout=0.1, activation='gelu')(t)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "controversial-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TST(Module):\n",
    "    def __init__(self, c_in:int, c_out:int, seq_len:int, max_seq_len:Optional[int]=None, \n",
    "                 n_layers:int=3, d_model:int=128, n_heads:int=16, d_k:Optional[int]=None, d_v:Optional[int]=None,  \n",
    "                 d_ff:int=256, res_dropout:float=0.1, act:str=\"gelu\", fc_dropout:float=0., \n",
    "                 y_range:Optional[tuple]=None, verbose:bool=False, **kwargs):\n",
    "        r\"\"\"TST (Time Series Transformer) is a Transformer that takes continuous time series as inputs.\n",
    "        As mentioned in the paper, the input must be standardized by_var based on the entire training set.\n",
    "        Args:\n",
    "            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset.\n",
    "            c_out: the number of target classes.\n",
    "            seq_len: number of time steps in the time series.\n",
    "            max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues.\n",
    "            d_model: total dimension of the model (number of features created by the model)\n",
    "            n_heads:  parallel attention heads.\n",
    "            d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.\n",
    "            d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.\n",
    "            d_ff: the dimension of the feedforward network model.\n",
    "            res_dropout: amount of residual dropout applied in the encoder.\n",
    "            act: the activation function of intermediate layer, relu or gelu.\n",
    "            num_layers: the number of sub-encoder-layers in the encoder.\n",
    "            fc_dropout: dropout applied to the final fully connected layer.\n",
    "            y_range: range of possible y values (used in regression tasks).\n",
    "            kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.\n",
    "\n",
    "        Input shape:\n",
    "            bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)\n",
    "        \"\"\"\n",
    "        self.c_out, self.seq_len = c_out, seq_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = seq_len\n",
    "        self.new_q_len = False\n",
    "        if max_seq_len is not None and seq_len > max_seq_len: # Control temporal resolution\n",
    "            self.new_q_len = True\n",
    "            q_len = max_seq_len\n",
    "            tr_factor = math.ceil(seq_len / q_len)\n",
    "            total_padding = (tr_factor * q_len - seq_len)\n",
    "            padding = (total_padding // 2, total_padding - total_padding // 2)\n",
    "            self.W_P = nn.Sequential(Pad1d(padding), Conv1d(c_in, d_model, kernel_size=tr_factor, stride=tr_factor))\n",
    "            pv(f'temporal resolution modified: {seq_len} --> {q_len} time steps: kernel_size={tr_factor}, stride={tr_factor}, padding={padding}.\\n', verbose)\n",
    "        elif kwargs:\n",
    "            self.new_q_len = True\n",
    "            t = torch.rand(1, 1, seq_len)\n",
    "            q_len = nn.Conv1d(1, 1, **kwargs)(t).shape[-1]\n",
    "            self.W_P = nn.Conv1d(c_in, d_model, **kwargs) # Eq 2\n",
    "            pv(f'Conv1d with kwargs={kwargs} applied to input to create input encodings\\n', verbose)\n",
    "        else:\n",
    "            self.W_P = nn.Linear(c_in, d_model) # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "\n",
    "        # Positional encoding\n",
    "        W_pos = torch.zeros((q_len, d_model), device=default_device())\n",
    "        self.W_pos = nn.Parameter(W_pos, requires_grad=True)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.res_dropout = nn.Dropout(res_dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = _TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, activation=act, n_layers=n_layers)\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        # Head\n",
    "        self.head_nf = q_len * d_model\n",
    "        self.head = self.create_head(self.head_nf, c_out, fc_dropout=fc_dropout, y_range=y_range)\n",
    "\n",
    "    def create_head(self, nf, c_out, fc_dropout=0., y_range=None, **kwargs):\n",
    "        layers = [nn.Dropout(fc_dropout)] if fc_dropout else []\n",
    "        layers += [nn.Linear(nf, c_out)]\n",
    "        if y_range: layers += [SigmoidRange(*y_range)]\n",
    "        return nn.Sequential(*layers)    \n",
    "        \n",
    "\n",
    "    def forward(self, x:Tensor, mask:Optional[Tensor]=None) -> Tensor:  # x: [bs x nvars x q_len]\n",
    "\n",
    "        # Input encoding\n",
    "        if self.new_q_len: u = self.W_P(x).transpose(2,1) # Eq 2        # u: [bs x d_model x q_len] transposed to [bs x q_len x d_model]\n",
    "        else: u = self.W_P(x.transpose(2,1)) # Eq 1                     # u: [bs x q_len x nvars] converted to [bs x q_len x d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        u = self.res_dropout(u + self.W_pos)\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                             # z: [bs x q_len x d_model]\n",
    "        if self.flatten is not None: z = self.flatten(z)                # z: [bs x q_len * d_model]\n",
    "        else: z = z.transpose(2,1).contiguous()                         # z: [bs x d_model x q_len]\n",
    "\n",
    "        # Classification/ Regression head\n",
    "        return self.head(z)                                             # output: [bs x c_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "stable-parallel",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_MultiheadAttention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-bbfa196abb1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m model = TST(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,\n\u001b[1;32m     24\u001b[0m             \u001b[0md_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_dropout\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             fc_dropout=fc_dropout, **kwargs)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#test_eq(model(xb).shape, [bs, c_out])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'model parameters: {count_parameters(model)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-266-a9ae7b6f5e5a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, c_in, c_out, seq_len, max_seq_len, n_layers, d_model, n_heads, d_k, d_v, d_ff, res_dropout, act, fc_dropout, y_range, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TSTEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-a4d6bd23f474>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, q_len, d_model, n_heads, d_k, d_v, d_ff, res_dropout, activation, n_layers)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         self.layers = nn.ModuleList([_TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, \n\u001b[0;32m----> 6\u001b[0;31m                                                             activation=activation) for i in range(n_layers)])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-a4d6bd23f474>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         self.layers = nn.ModuleList([_TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, \n\u001b[0;32m----> 6\u001b[0;31m                                                             activation=activation) for i in range(n_layers)])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-15cbaedb67b7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, q_len, d_model, n_heads, d_k, d_v, d_ff, store_attn, res_dropout, bias, activation, res_attention, pre_norm)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Multi-Head attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MultiheadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Add & Norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_MultiheadAttention' is not defined"
     ]
    }
   ],
   "source": [
    "bs = 575\n",
    "c_in = 9  # aka channels, features, variables, dimensions\n",
    "c_out = 24\n",
    "seq_len = 144\n",
    "\n",
    "#xb = torch.randn(bs, c_in, seq_len)\n",
    "\n",
    "# standardize by channel by_var based on the training set\n",
    "#xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)\n",
    "\n",
    "# Settings\n",
    "max_seq_len = 256\n",
    "d_model = 128\n",
    "n_heads = 16\n",
    "d_k = d_v = None # if None --> d_model // n_heads\n",
    "d_ff = 256\n",
    "res_dropout = 0.1\n",
    "activation = \"gelu\"\n",
    "n_layers = 3\n",
    "fc_dropout = 0.1\n",
    "kwargs = {}\n",
    "\n",
    "model = TST(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,\n",
    "            d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout,  n_layers=n_layers,\n",
    "            fc_dropout=fc_dropout, **kwargs)\n",
    "#test_eq(model(xb).shape, [bs, c_out])\n",
    "print(f'model parameters: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "handy-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, idx_train, idx_val, idx_test, nclass = load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\", dataset = 'ArticularyWordRecognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "danish-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([575, 9, 144])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "eleven-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(model(features).shape, [bs, c_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "stylish-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TST(\n",
       "  (W_P): Linear(in_features=9, out_features=128, bias=True)\n",
       "  (res_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (encoder): _TSTEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): _TSTEncoderLayer(\n",
       "        (self_attn): _MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_K): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_V): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_O): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (dropout_attn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_attn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout_ffn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_ffn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): _TSTEncoderLayer(\n",
       "        (self_attn): _MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_K): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_V): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_O): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (dropout_attn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_attn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout_ffn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_ffn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): _TSTEncoderLayer(\n",
       "        (self_attn): _MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_K): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_V): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (W_O): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (dropout_attn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_attn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout_ffn): Dropout(p=0.1, inplace=False)\n",
       "        (batchnorm_ffn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (flatten): Flatten(full=False)\n",
       "  (head): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=18432, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "superb-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters: 419410\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "c_in = 9  # aka channels, features, variables, dimensions\n",
    "c_out = 2\n",
    "seq_len = 60\n",
    "\n",
    "xb = torch.randn(bs, c_in, seq_len)\n",
    "\n",
    "# standardize by channel by_var based on the training set\n",
    "xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)\n",
    "\n",
    "# Settings\n",
    "max_seq_len = 120\n",
    "d_model = 128\n",
    "n_heads = 16\n",
    "d_k = d_v = None # if None --> d_model // n_heads\n",
    "d_ff = 256\n",
    "res_dropout = 0.1\n",
    "act = \"gelu\"\n",
    "n_layers = 3\n",
    "fc_dropout = 0.1\n",
    "kwargs = {}\n",
    "# kwargs = dict(kernel_size=5, padding=2)\n",
    "\n",
    "model = TST(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,\n",
    "            d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, act=act, n_layers=n_layers,\n",
    "            fc_dropout=fc_dropout, **kwargs)\n",
    "test_eq(model(xb).shape, [bs, c_out])\n",
    "print(f'model parameters: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-visitor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "tracked-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "class _TSTEncoderLayer(Module):\n",
    "    def __init__(self, q_len:int, d_model:int, n_heads:int, d_k:Optional[int]=None, d_v:Optional[int]=None, d_ff:int=256, store_attn:bool=False,\n",
    "                 res_dropout:float=0., bias:bool=True, activation:str=\"gelu\", res_attention:bool=False, pre_norm:bool=False):\n",
    "\n",
    "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = ifnone(d_k, d_model // n_heads)\n",
    "        d_v = ifnone(d_v, d_model // n_heads)\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(res_dropout)\n",
    "        self.batchnorm_attn = nn.BatchNorm1d(q_len)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias), self._get_activation_fn(activation), nn.Linear(d_ff, d_model, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(res_dropout)\n",
    "        self.batchnorm_ffn = nn.BatchNorm1d(q_len)\n",
    "        \n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.batchnorm_attn(src) # Norm: batchnorm \n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn: \n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.batchnorm_attn(src) # Norm: batchnorm \n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.batchnorm_ffn(src) # Norm: batchnorm\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.batchnorm_ffn(src) # Norm: batchnorm\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "    def _get_activation_fn(self, activation):\n",
    "        if callable(activation): return activation()\n",
    "        elif activation.lower() == \"relu\": return nn.ReLU()\n",
    "        elif activation.lower() == \"gelu\": return nn.GELU()\n",
    "        raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "musical-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_mask torch.Size([50, 50]) key_padding_mask torch.Size([16, 50])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_MultiheadAttention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-ce46994fb777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'key_padding_mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TSTEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_attn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gelu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-15cbaedb67b7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, q_len, d_model, n_heads, d_k, d_v, d_ff, store_attn, res_dropout, bias, activation, res_attention, pre_norm)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Multi-Head attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MultiheadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Add & Norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_MultiheadAttention' is not defined"
     ]
    }
   ],
   "source": [
    "t = torch.rand(16, 50, 128)\n",
    "attn_mask = torch.triu(torch.ones(50, 50)) # shape: q_len x q_len\n",
    "key_padding_mask = torch.zeros(16, 50)\n",
    "key_padding_mask[[1, 3, 6, 15], -10:] = 1\n",
    "key_padding_mask = key_padding_mask.bool()\n",
    "print('attn_mask', attn_mask.shape, 'key_padding_mask', key_padding_mask.shape)\n",
    "encoder = _TSTEncoderLayer(q_len=50, d_model=128, n_heads=8, d_k=None, d_v=None, d_ff=512, res_dropout=0.1, store_attn=True, activation='gelu')\n",
    "output = encoder(t, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "emerging-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "employed-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "lyric-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlockPlus(Module):\n",
    "    def __init__(self, ni, nf, residual=True, depth=6, coord=False, norm='Batch', zero_norm=False, act=nn.ReLU, act_kwargs={}, sa=False, se=None,\n",
    "                 stoch_depth=1., **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut, self.act = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModulePlus(ni if d == 0 else nf * 4, nf, coord=coord, norm=norm,\n",
    "                                                      zero_norm=zero_norm if d % 3 == 2 else False,\n",
    "                                                      act=act if d % 3 != 2 else None, act_kwargs=act_kwargs,\n",
    "                                                      sa=sa if d % 3 == 2 else False,\n",
    "                                                      se=se if d % 3 != 2 else None,\n",
    "                                                      **kwargs))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(Norm(n_in, norm=norm) if n_in == n_out else ConvBlock(n_in, n_out, 1, coord=coord, bias=False, norm=norm, act=None))\n",
    "                self.act.append(act(**act_kwargs))\n",
    "        self.add = Add()\n",
    "        if stoch_depth != 0: keep_prob = np.linspace(1, stoch_depth, depth)\n",
    "        else: keep_prob = np.array([1] * depth)\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for i in range(self.depth):\n",
    "            if self.keep_prob[i] > random.random() or not self.training:\n",
    "                x = self.inception[i](x)\n",
    "            if self.residual and i % 3 == 2:\n",
    "                res = x = self.act[i//3](self.add(x, self.shortcut[i//3](res)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "linear-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TSiTEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers:int=6, attn_drop_rate:float=0, mlp_drop_rate:float=0, drop_path_rate:float=0.,\n",
    "                 mlp_ratio:int=1, qkv_bias:bool=True, act:str='reglu', pre_norm:bool=False):\n",
    "        super().__init__()\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, n_layers)]\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                MultiheadAttention(d_model, n_heads, dropout=attn_drop_rate, qkv_bias=qkv_bias), nn.LayerNorm(d_model),\n",
    "                PositionwiseFeedForward(d_model, dropout=mlp_drop_rate, act=act, mlp_ratio=mlp_ratio), nn.LayerNorm(d_model),\n",
    "                # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "                DropPath(dpr[i]) if dpr[i] != 0 else nn.Identity(),\n",
    "                # nn.Dropout(drop_path_rate) if drop_path_rate != 0 else nn.Identity()\n",
    "            ]))\n",
    "        self.pre_norm = pre_norm\n",
    "        self.norm = nn.LayerNorm(d_model) if self.pre_norm else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, (mha, attn_norm, pwff, ff_norm, drop_path) in enumerate(self.layers):\n",
    "            if self.pre_norm:\n",
    "                x = drop_path(mha(attn_norm(x))[0]) + x\n",
    "                x = drop_path(pwff(ff_norm(x))) + x\n",
    "            else:\n",
    "                x = attn_norm(drop_path(mha(x)[0]) + x)\n",
    "                x = ff_norm(drop_path(pwff(x)) + x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class _TSiTBackbone(Module):\n",
    "    def __init__(self, c_in:int, seq_len:int, n_layers:int=6, d_model:int=128, n_heads:int=16, d_head:Optional[int]=None, act:str='reglu',\n",
    "                 d_ff:int=256, qkv_bias:bool=True, pos_dropout:float=0., attn_drop_rate:float=0, mlp_drop_rate:float=0, drop_path_rate:float=0.,\n",
    "                 mlp_ratio:int=1, pre_norm:bool=False, use_token:bool=True, ks:Optional[int]=None, maxpool:bool=True,\n",
    "                 preprocessor:Optional[Callable]=None, device=None, verbose:bool=False):\n",
    "\n",
    "        device = ifnone(device, default_device())\n",
    "        self.preprocessor = nn.Identity()\n",
    "        if preprocessor is not None:\n",
    "            xb = torch.randn(1, c_in, seq_len).to(device)\n",
    "            ori_c_in, ori_seq_len = c_in, seq_len\n",
    "            if not isinstance(preprocessor, nn.Module): preprocessor = preprocessor(c_in, d_model).to(device)\n",
    "            else: preprocessor = preprocessor.to(device)\n",
    "            with torch.no_grad():\n",
    "                # NOTE Most reliable way of determining output dims is to run forward pass\n",
    "                training = preprocessor.training\n",
    "                if training:\n",
    "                    preprocessor.eval()\n",
    "                c_in, seq_len = preprocessor(xb).shape[1:]\n",
    "                preprocessor.train(training)\n",
    "            pv(f'preprocessor: (?, {ori_c_in}, {ori_seq_len}) --> (?, {c_in}, {seq_len})', verbose=verbose)\n",
    "            self.preprocessor = preprocessor\n",
    "\n",
    "        if seq_len == d_model:\n",
    "            self.to_embedding = Transpose(1,2)\n",
    "        elif ks is not None:\n",
    "            self.to_embedding = nn.Sequential(MultiConcatConv1d(c_in, d_model, kss=ks, maxpool=maxpool),Transpose(1,2))\n",
    "        else:\n",
    "            self.to_embedding = nn.Sequential(Conv1d(c_in, d_model, 1),Transpose(1,2))\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, seq_len, d_model))\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.use_token = use_token\n",
    "        self.pos_dropout = nn.Dropout(pos_dropout)\n",
    "\n",
    "        self.encoder = _TSiTEncoder(d_model, n_heads, n_layers=n_layers, qkv_bias=qkv_bias, attn_drop_rate=attn_drop_rate, mlp_drop_rate=mlp_drop_rate,\n",
    "                                    mlp_ratio=mlp_ratio, drop_path_rate=drop_path_rate, act=act, pre_norm=pre_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # apply preprocessor module if exists\n",
    "        x = self.preprocessor(x)\n",
    "\n",
    "        # embedding\n",
    "        x = self.to_embedding(x)\n",
    "        x = x + self.pos_embedding\n",
    "        if self.use_token:\n",
    "            x = torch.cat((self.cls_token.expand(x.shape[0], -1, -1), x), dim=1)\n",
    "        x = self.pos_dropout(x)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = x.transpose(1,2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TSiTPlus(nn.Sequential):\n",
    "    \"\"\"Time series transformer model based on ViT (Vision Transformer):\n",
    "    Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020).\n",
    "    An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n",
    "    This implementation is a modified version of Vision Transformer that is part of the grat timm library\n",
    "    (https://github.com/rwightman/pytorch-image-models/blob/72b227dcf57c0c62291673b96bdc06576bb90457/timm/models/vision_transformer.py)\n",
    "    Args:\n",
    "    =====\n",
    "    c_in:                   the number of features (aka variables, dimensions, channels) in the time series dataset.\n",
    "    c_out:                  the number of target classes.\n",
    "    seq_len:                number of time steps in the time series.\n",
    "    n_layers:               number of layers (or blocks) in the encoder. Default: 3 (range(1-4))\n",
    "    d_model:                total dimension of the model (number of features created by the model). Default: 128 (range(64-512))\n",
    "    n_heads:                parallel attention heads. Default:16 (range(8-16)).\n",
    "    d_head:                 size of the learned linear projection of queries, keys and values in the MHA. Usual values: 16-512.\n",
    "                            Default: None -> (d_model/n_heads) = 32.\n",
    "    act:                    the activation function of intermediate layer, relu, gelu, geglu, reglu.\n",
    "    d_ff:                   the dimension of the feedforward network model. Default: 512 (range(256-512))\n",
    "    pos_dropout:            dropout applied to to the embedded sequence steps after position embeddings have been added.\n",
    "    attn_drop_rate (float): dropout rate applied to the attention layer\n",
    "    mlp_drop_rate (float):  dropout rate applied to the mlp layer\n",
    "    drop_path_rate:         dropout applied to the output of MultheadAttention and PositionwiseFeedForward layers.\n",
    "    mlp_ratio:              ratio of mlp hidden dim to embedding dim.\n",
    "    qkv_bias:               determines whether bias is applied to the Linear projections of queries, keys and values in the MultiheadAttention\n",
    "    pre_norm:               if True normalization will be applied as the first step in the sublayers. Defaults to False.\n",
    "    use_token:              if True, the output will come from the transformed token. Otherwise a pooling layer will be applied.\n",
    "    fc_dropout:             dropout applied to the final fully connected layer.\n",
    "    bn:                     indicates if batchnorm will be applied to the head.\n",
    "    y_range:                range of possible y values (used in regression tasks).\n",
    "    ks:                     (Optional) kernel sizes that will be applied to a hybrid embedding.\n",
    "    maxpool:                If true and kernel sizes are passed, maxpool will also be added to the hybrid embedding.\n",
    "    preprocessor:           an optional callable (nn.Conv1d with dilation > 1 or stride > 1 for example) that will be used to preprocess the time series before\n",
    "                            the embedding step. It is useful to extract features or resample the time series.\n",
    "    custom_head:            custom head that will be applied to the network. It must contain all kwargs (pass a partial function)\n",
    "    Input shape:\n",
    "        x: bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, c_in:int, c_out:int, seq_len:int, n_layers:int=6, d_model:int=128, n_heads:int=16, d_head:Optional[int]=None, act:str='reglu',\n",
    "                 d_ff:int=256, pos_dropout:float=0., attn_drop_rate:float=0, mlp_drop_rate:float=0, drop_path_rate:float=0., mlp_ratio:int=1,\n",
    "                 qkv_bias:bool=True, pre_norm:bool=False, use_token:bool=True, fc_dropout:float=0., bn:bool=True, y_range:Optional[tuple]=None,\n",
    "                 ks:Optional[int]=None, maxpool:bool=True, preprocessor:Optional[Callable]=None, custom_head:Optional[Callable]=None, verbose:bool=False):\n",
    "\n",
    "        backbone = _TSiTBackbone(c_in, seq_len, n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_head=d_head, act=act,\n",
    "                                          d_ff=d_ff, pos_dropout=pos_dropout, attn_drop_rate=attn_drop_rate, mlp_drop_rate=mlp_drop_rate,\n",
    "                                          drop_path_rate=drop_path_rate, pre_norm=pre_norm, mlp_ratio=mlp_ratio, use_token=use_token,\n",
    "                                          ks=ks, maxpool=maxpool, preprocessor=preprocessor, verbose=verbose)\n",
    "\n",
    "        self.head_nf = d_model\n",
    "        self.c_out = c_out\n",
    "        self.seq_len = seq_len\n",
    "        if custom_head:\n",
    "            head = custom_head(self.head_nf, c_out, self.seq_len) # custom head passed as a partial func with all its kwargs\n",
    "        else:\n",
    "            layers = [TokenLayer(token=use_token)]\n",
    "            layers += [LinBnDrop(d_model, c_out, bn=bn, p=fc_dropout)]\n",
    "            if y_range: layers += [SigmoidRange(*y_range)]\n",
    "            head = nn.Sequential(*layers)\n",
    "\n",
    "        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))\n",
    "\n",
    "\n",
    "TSiT = TSiTPlus\n",
    "\n",
    "InceptionTSiTPlus = partial(TSiTPlus, preprocessor=partial(InceptionBlockPlus, ks=[3,5,7]))\n",
    "setattr(InceptionTSiTPlus, \"__name__\", \"InceptionTSiTPlus\")\n",
    "\n",
    "InceptionTSiT = InceptionTSiTPlus\n",
    "setattr(InceptionTSiT, \"__name__\", \"InceptionTSiT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-hungarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-zealand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-supervision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "posted-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "disabled-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import MultiheadAttention, Linear, Dropout, BatchNorm1d, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "included-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "    raise ValueError(\"activation should be relu/gelu, not {}\".format(activation))\n",
    "\n",
    "\n",
    "# From https://github.com/pytorch/examples/blob/master/word_language_model/model.py\n",
    "class FixedPositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
    "        in the sequence. The positional encodings have the same dimension as\n",
    "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
    "        functions of different frequencies.\n",
    "    .. math::\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=1024).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1024, scale_factor=1.0):\n",
    "        super(FixedPositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # positional encoding\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = scale_factor * pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)  # this stores the variable in the state_dict (used for non-trainable variables)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "def get_pos_encoder(pos_encoding):\n",
    "    if pos_encoding == \"learnable\":\n",
    "        return LearnablePositionalEncoding\n",
    "    elif pos_encoding == \"fixed\":\n",
    "        return FixedPositionalEncoding\n",
    "\n",
    "    raise NotImplementedError(\"pos_encoding should be 'learnable'/'fixed', not '{}'\".format(pos_encoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expected-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBatchNormEncoderLayer(nn.modules.Module):\n",
    "    \n",
    "    r\"\"\"This transformer encoder layer block is made up of self-attn and feedforward network.\n",
    "    It differs from TransformerEncoderLayer in torch/nn/modules/transformer.py in that it replaces LayerNorm\n",
    "    with BatchNorm.\n",
    "    Args:\n",
    "        d_model: the number of expected features in the input (required).\n",
    "        nhead: the number of heads in the multiheadattention models (required).\n",
    "        dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(TransformerBatchNormEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = Linear(d_model, dim_feedforward)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.linear2 = Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = BatchNorm1d(d_model, eps=1e-5)  # normalizes each feature across batch samples and time steps\n",
    "        self.norm2 = BatchNorm1d(d_model, eps=1e-5)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(TransformerBatchNormEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None,\n",
    "                src_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "        Args:\n",
    "            src: the sequence to the encoder layer (required).\n",
    "            src_mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                              key_padding_mask=src_key_padding_mask)[0]\n",
    "        src = src + self.dropout1(src2)  # (seq_len, batch_size, d_model)\n",
    "        src = src.permute(1, 2, 0)  # (batch_size, d_model, seq_len)\n",
    "        # src = src.reshape([src.shape[0], -1])  # (batch_size, seq_length * d_model)\n",
    "        src = self.norm1(src)\n",
    "        src = src.permute(2, 0, 1)  # restore (seq_len, batch_size, d_model)\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)  # (seq_len, batch_size, d_model)\n",
    "        src = src.permute(1, 2, 0)  # (batch_size, d_model, seq_len)\n",
    "        src = self.norm2(src)\n",
    "        src = src.permute(2, 0, 1)  # restore (seq_len, batch_size, d_model)\n",
    "        return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lasting-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSTransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, dropout=0.1,\n",
    "                 pos_encoding='fixed', activation='gelu', norm='BatchNorm', freeze=False):\n",
    "        super(TSTransformerEncoder, self).__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.project_inp = nn.Linear(feat_dim, d_model)\n",
    "        self.pos_enc = get_pos_encoder(pos_encoding)(d_model, dropout=dropout*(1.0 - freeze), max_len=max_len)\n",
    "\n",
    "        if norm == 'LayerNorm':\n",
    "            encoder_layer = TransformerEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
    "        else:\n",
    "            encoder_layer = TransformerBatchNormEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(d_model, feat_dim)\n",
    "\n",
    "        self.act = _get_activation_fn(activation)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def forward(self, X, padding_masks):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: (batch_size, seq_length, feat_dim) torch tensor of masked features (input)\n",
    "            padding_masks: (batch_size, seq_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "        Returns:\n",
    "            output: (batch_size, seq_length, feat_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        # permute because pytorch convention for transformers is [seq_length, batch_size, feat_dim]. padding_masks [batch_size, feat_dim]\n",
    "        inp = X.permute(1, 0, 2)\n",
    "        inp = self.project_inp(inp) * math.sqrt(\n",
    "            self.d_model)  # [seq_length, batch_size, d_model] project input vectors to d_model dimensional space\n",
    "        inp = self.pos_enc(inp)  # add positional encoding\n",
    "        # NOTE: logic for padding masks is reversed to comply with definition in MultiHeadAttention, TransformerEncoderLayer\n",
    "        output = self.transformer_encoder(inp, src_key_padding_mask=~padding_masks)  # (seq_length, batch_size, d_model)\n",
    "        output = self.act(output)  # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = output.permute(1, 0, 2)  # (batch_size, seq_length, d_model)\n",
    "        output = self.dropout1(output)\n",
    "        # Most probably defining a Linear(d_model,feat_dim) vectorizes the operation over (seq_length, batch_size).\n",
    "        output = self.output_layer(output)  # (batch_size, seq_length, feat_dim)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "challenging-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSTransformerEncoderClassiregressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplest classifier/regressor. Can be either regressor or classifier because the output does not include\n",
    "    softmax. Concatenates final layer embeddings and uses 0s to ignore padding embeddings in final output layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feat_dim, max_len, d_model, n_heads, num_layers, dim_feedforward, num_classes,\n",
    "                 dropout=0.1, pos_encoding='fixed', activation='gelu', norm='BatchNorm', freeze=False):\n",
    "        super(TSTransformerEncoderClassiregressor, self).__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.project_inp = nn.Linear(feat_dim, d_model)\n",
    "        self.pos_enc = get_pos_encoder(pos_encoding)(d_model, dropout=dropout*(1.0 - freeze), max_len=max_len)\n",
    "\n",
    "        if norm == 'LayerNorm':\n",
    "            encoder_layer = TransformerEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
    "        else:\n",
    "            encoder_layer = TransformerBatchNormEncoderLayer(d_model, self.n_heads, dim_feedforward, dropout*(1.0 - freeze), activation=activation)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        self.act = _get_activation_fn(activation)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.output_layer = self.build_output_module(d_model, max_len, num_classes)\n",
    "\n",
    "    def build_output_module(self, d_model, max_len, num_classes):\n",
    "        output_layer = nn.Linear(d_model * max_len, num_classes)\n",
    "        # no softmax (or log softmax), because CrossEntropyLoss does this internally. If probabilities are needed,\n",
    "        # add F.log_softmax and use NLLoss\n",
    "        return output_layer\n",
    "\n",
    "    def forward(self, X, padding_masks):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: (batch_size, seq_length, feat_dim) torch tensor of masked features (input)\n",
    "            padding_masks: (batch_size, seq_length) boolean tensor, 1 means keep vector at this position, 0 means padding\n",
    "        Returns:\n",
    "            output: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # permute because pytorch convention for transformers is [seq_length, batch_size, feat_dim]. padding_masks [batch_size, feat_dim]\n",
    "        inp = X.permute(1, 0, 2)\n",
    "        inp = self.project_inp(inp) * math.sqrt(\n",
    "            self.d_model)  # [seq_length, batch_size, d_model] project input vectors to d_model dimensional space\n",
    "        inp = self.pos_enc(inp)  # add positional encoding\n",
    "        # NOTE: logic for padding masks is reversed to comply with definition in MultiHeadAttention, TransformerEncoderLayer\n",
    "        output = self.transformer_encoder(inp, src_key_padding_mask=~padding_masks)  # (seq_length, batch_size, d_model)\n",
    "        output = self.act(output)  # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = output.permute(1, 0, 2)  # (batch_size, seq_length, d_model)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    "        # Output\n",
    "        output = output * padding_masks.unsqueeze(-1)  # zero-out padding embeddings\n",
    "        output = output.reshape(output.shape[0], -1)  # (batch_size, seq_length * d_model)\n",
    "        output = self.output_layer(output)  # (batch_size, num_classes)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "broken-grain",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "expecting key_padding_mask shape of (360, 24), but got torch.Size([360, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_9506/2136849841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_9506/3271735479.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, padding_masks)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add positional encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# NOTE: logic for padding masks is reversed to comply with definition in MultiHeadAttention, TransformerEncoderLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpadding_masks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_length, batch_size, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the output transformer encoder/decoder embeddings don't include non-linearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_length, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/tp/r9md9jss78nf28s4cq7vcg580000gn/T/ipykernel_9506/3144211386.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[1;32m     44\u001b[0m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0;32m---> 45\u001b[0;31m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, batch_size, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, d_model, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Tensorflow/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey_padding_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5058\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5059\u001b[0;31m             \u001b[0;34mf\"expecting key_padding_mask shape of {(bsz, src_len)}, but got {key_padding_mask.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5060\u001b[0m         \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5061\u001b[0m             \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: expecting key_padding_mask shape of (360, 24), but got torch.Size([360, 1])"
     ]
    }
   ],
   "source": [
    "model(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "varying-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSTransformerEncoderClassiregressor(51, 360, 24, 1, 10, 10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-thing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cosmetic-competition",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 7 required positional arguments: 'feat_dim', 'max_len', 'd_model', 'n_heads', 'num_layers', 'dim_feedforward', and 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-9279cbc5566e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTSTransformerEncoderClassiregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 7 required positional arguments: 'feat_dim', 'max_len', 'd_model', 'n_heads', 'num_layers', 'dim_feedforward', and 'num_classes'"
     ]
    }
   ],
   "source": [
    "TSTransformerEncoderClassiregressor()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wanted-criterion",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "        Args:\n",
    "            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset\n",
    "            c_out: the number of target classes\n",
    "            d_model: total dimension of the model.\n",
    "            nhead:  parallel attention heads.\n",
    "            d_ffn: the dimension of the feedforward network model.\n",
    "            dropout: a Dropout layer on attn_output_weights.\n",
    "            activation: the activation function of intermediate layer, relu or gelu.\n",
    "            num_layers: the number of sub-encoder-layers in the encoder.\n",
    "        Input shape:\n",
    "            bs (batch size) x nvars (aka variables, dimensions, channels) x seq_len (aka time steps)\n",
    "            \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liquid-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, idx_train, idx_val, idx_test, nclass = \\\n",
    "                        load_raw_ts(\"/Users/abhijitdeshpande/Documents/Thesis/tapnet_converted_data/tapnet_converted_data/data/\",\n",
    "                                                                      dataset = 'NATOPS')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stylish-makeup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([360, 24, 51])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sensitive-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([360, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-vintage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c22c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
